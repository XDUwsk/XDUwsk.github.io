<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="YOLOv6: A Single-Stage Object Detection Framework for Industrial  ApplicationsYOLOv6发现以往的模型存在以下问题： 来自RepVGG的重参数化是一种尚未在检测中得到很好利用的优越技术。我们还注意到，对于RepVGG块，简单的模型缩放变得不切实际，因此我们认为小型和大型网络之间的网络设计的优雅一致性是不必要的。对于小型">
<meta property="og:type" content="article">
<meta property="og:title" content="YOLOv6 A Single-Stage Object Detection Framework for Industrial  Applications">
<meta property="og:url" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/index.html">
<meta property="og:site_name" content="凯_kaiii">
<meta property="og:description" content="YOLOv6: A Single-Stage Object Detection Framework for Industrial  ApplicationsYOLOv6发现以往的模型存在以下问题： 来自RepVGG的重参数化是一种尚未在检测中得到很好利用的优越技术。我们还注意到，对于RepVGG块，简单的模型缩放变得不切实际，因此我们认为小型和大型网络之间的网络设计的优雅一致性是不必要的。对于小型">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/b55cad01c6aa466c8df35624466f1a49.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/b55cad01c6aa466c8df35624466f1a49-16867300125633.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/17095d3e9d894251b1542f04500d7653.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/9ef8cfa56b40480e94f5ce1b36eb5875.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/70e48551855e4598af43ca460c462046.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/956c6028740d47c398f7ef336d6e5ffb.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/2421a4e7d6da4247af9d11f7fefe46dc.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/7628f443735a4c1e9c0a75518ea107e7.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/1879de4162f44bb080647818d6350ce4.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/408b78b8e84d40c590319c35205855c0.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/88873d7d91d945c79f54014e725fbe13.png">
<meta property="og:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/cda38d2ac2884096b174b6dc66edbb6e-168707903752712.png">
<meta property="article:published_time" content="2023-06-18T09:03:19.000Z">
<meta property="article:modified_time" content="2023-06-18T09:04:07.069Z">
<meta property="article:author" content="凯">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/b55cad01c6aa466c8df35624466f1a49.png">

<link rel="canonical" href="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>YOLOv6 A Single-Stage Object Detection Framework for Industrial  Applications | 凯_kaiii</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">凯_kaiii</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">暂无</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="凯">
      <meta itemprop="description" content="选择大于努力">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="凯_kaiii">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          YOLOv6 A Single-Stage Object Detection Framework for Industrial  Applications
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-06-18 17:03:19 / 修改时间：17:04:07" itemprop="dateCreated datePublished" datetime="2023-06-18T17:03:19+08:00">2023-06-18</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications"><a href="#YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications" class="headerlink" title="YOLOv6: A Single-Stage Object Detection Framework for Industrial  Applications"></a>YOLOv6: A Single-Stage Object Detection Framework for Industrial  Applications</h1><h2 id="YOLOv6发现以往的模型存在以下问题："><a href="#YOLOv6发现以往的模型存在以下问题：" class="headerlink" title="YOLOv6发现以往的模型存在以下问题："></a>YOLOv6发现以往的模型存在以下问题：</h2><ul>
<li>来自RepVGG的重参数化是一种尚未在检测中得到很好利用的优越技术。我们还注意到，对于RepVGG块，简单的模型缩放变得不切实际，因此我们认为小型和大型网络之间的网络设计的优雅一致性是不必要的。对于小型网络，简单的单路径架构是更好的选择，但对于大型模型，单路径架构的参数和计算成本的指数增长使其不可行</li>
<li>基于重参数化的检测器的量化也需要细致的处理，否则在训练和推理过程中由于其异构配置而导致的性能下降将难以处理。</li>
<li>以前的工作往往不太关注部署，其延迟通常在V100等高成本机器上进行比较。当涉及到真正的服务环境时，存在硬件差距。通常，像Tesla T4这样的低功耗gpu成本更低，并且提供相当好的推理性能。</li>
<li>考虑到架构差异，标签分配和损失函数设计等高级领域特定策略需要进一步验证;</li>
<li>对于部署，我们可以容忍训练策略的调整，以提高精度性能，但不增加推理成本，例如知识蒸馏。</li>
</ul>
<h2 id="本文的主要工作"><a href="#本文的主要工作" class="headerlink" title="本文的主要工作"></a>本文的主要工作</h2><ul>
<li>我们重新设计了一系列不同规模的网络，为不同场景的工业应用量身定制。</li>
<li>不同规模的架构不同，以实现最佳的速度和精度权衡，其中小模型具有简单的单路径主干，而大模型构建在高效的多分支块上。</li>
<li>我们为YOLOv6注入了一种自蒸馏策略，同时执行分类任务和回归任务。同时，我们动态调整来自老师和标签的知识，帮助学生模型在所有训练阶段更有效地学习知识。</li>
<li>我们广泛验证了标签分配、损失函数和数据增强技术的先进检测技术，并有选择地采用它们来进一步提高性能。</li>
<li>我们在RepOptimizer和通道式蒸馏的帮助下，对检测的量化方案进行了改革，这导致了一个永远快速和准确的检测器，在batchsize大小为32时，具有43.3%的COCO AP和869 FPS的吞吐量。</li>
</ul>
<h2 id="使用的方法-amp-模型的具体结构"><a href="#使用的方法-amp-模型的具体结构" class="headerlink" title="使用的方法&amp;模型的具体结构"></a>使用的方法&amp;模型的具体结构</h2><p><img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/b55cad01c6aa466c8df35624466f1a49.png" alt="img"></p>
<ul>
<li><strong>网络设计</strong>:<ul>
<li><strong>backbone</strong>:与其他主流架构相比，我们发现在相似的推理速度下，RepVGG骨干网在<strong>小型网络</strong>中具有更强的特征表示能力，但由于参数和计算成本的爆炸式增长，它难以扩展以获得更大的模型。在这方面，我们将RepBlock作为我们小型网络的构建块。对于<strong>大型模型</strong>，我们修改了一个更有效的CSP块，命名为CSPStackRep块。</li>
<li><strong>neck</strong>:YOLOv6的颈部在YOLOv4和YOLOv5之后采用PAN拓扑。我们用RepBlocks或CSPStackRep Blocks增强颈部以获得RepPAN。</li>
<li><strong>head</strong>:我们简化了解耦头，使其更高效，称为高效解耦头。</li>
</ul>
</li>
<li><strong>标签分配</strong>:我们通过大量实验评估了标签分配策略的最新进展，结果表明<strong>TAL</strong>更有效，更适合训练。</li>
<li><strong>损失函数</strong>:主流无锚目标检测器的损失函数包含分类损失，anchor回归损失和对象损失。对于每一种损失，我们系统地用所有可用的技术进行实验，最终选择<strong>VariFocal loss</strong>作为我们的分类损失，<strong>SIoU/GIoU loss</strong>作为我们的回归损失</li>
<li><strong>行业便利的改进</strong>:我们引入了额外的常见做法和技巧来提高性能，包括<strong>自蒸馏</strong>和<strong>更多的训练epoch</strong>。分类和anchor回归分别由教师模型监督。由于DFL，anchor回归的精馏成为可能。此外，通过余弦衰减动态衰减软、硬标签信息的比例，帮助学员在训练过程中有选择地获取不同阶段的知识。此外，我们在评估中遇到了没有增加额外灰色边界的性能受损问题，对此我们提供了一些补救措施。</li>
<li><strong>量化和部署</strong>:为了解决基于再参数化的量化模型的性能下降问题，我们使用<strong>RepOptimizer</strong>训练YOLOv6，以获得ptq友好的权重。我们进一步采用QAT与通道智能蒸馏和图优化来追求极致的性能。</li>
</ul>
<h2 id="Network-Design"><a href="#Network-Design" class="headerlink" title="Network Design"></a>Network Design</h2><p>​    单阶段物体探测器通常由以下几个部分组成：主干、颈部和头部。主干网主要决定了特征表示能力，而其设计由于计算成本较大，对推理效率的影响很大。颈部用于将低级的物理特征与高级的语义特征进行聚合，然后在所有层次上建立金字塔形特征映射。头部由几个卷积层组成，并根据颈部组装的多层次特征来预测动态检测结果。从结构的角度来看，它可以分为基于锚头和无锚头，或者是参数耦合头和参数解耦头。 </p>
<p>​    在YOLOv6中，基于硬件友好的网络设计的原则，我们提出了两个缩放的可再参数化的骨干和颈，以适应不同大小的模型，以及一个有效的解耦与混合通道策略的头。YOLOv6的整体架构如图所示。</p>
<p><img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/b55cad01c6aa466c8df35624466f1a49-16867300125633.png" alt="img"></p>
<h3 id="Backbone"><a href="#Backbone" class="headerlink" title="Backbone"></a><strong>Backbone</strong></h3><p>​    多分支网络通常比单路径网络具有更好的分类性能，但它往往伴随着并行性的降低，并导致推理延迟的增加。相反，像VGG这样的普通单路网络具有高并行性和更少的内存占用的优点，从而获得了更高的推理效率。最近在RepVGG中，提出了一种结构重参数化方法，将训练时间的多分支拓扑与推理时间的平面架构解耦，以实现更好的速度精度权衡。</p>
<p>​     <strong>受上述工作的启发，我们设计了一个高效的可重新参数化的骨干，称为EffificientRep。对于小模型，训练阶段骨干的主要成分是RepBlock</strong>，如下图所示在推理阶段，每个RepBlock转换为3×3卷积层（表示为RepConv），具有ReLU激活函数，3×3卷积在主流gpu和cpu上得到了高度优化，并且它具有更高的计算密度。因此，高效的代表骨干网充分利用了硬件的计算能力，从而显著降低了推理延迟，同时提高了表示能力。</p>
<p>​    然而，<strong>随着模型容量的进一步扩大，单路网络中的计算成本和参数数量呈指数级增长。</strong>为了更好地实现计算负担和准确性之间的权衡，我们修改了CSPStackRep块来构建中大型网络的主干。如图所示，<strong>CSPStackRepBlock</strong>由三个1×1卷积层和一堆由两个RepVGGBlock或RepConv（分别在训练或推理时）组成，具有残差连接。此外，采用跨阶段部分（CSP）连接，在不增加计算成本的情况下提高性能。</p>
<p><img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/17095d3e9d894251b1542f04500d7653.png" alt="img"></p>
<h3 id="Neck"><a href="#Neck" class="headerlink" title="Neck"></a><strong>Neck</strong></h3><p>​    <strong>采用YOLO v4和YOLO v5的PAN结构，将RepBlock（用于小型模型）或CSPStackRep块替换为YOLOv5中使用的CSPBlock)，</strong>并相应地调整宽度和深度。YOLOv6的颈部被表示为Rep-PAN。 </p>
<h3 id="Head"><a href="#Head" class="headerlink" title="Head"></a><strong>Head</strong></h3><p>​    <strong>Effificient decoupled head：</strong> YOLOv5的检测头是一个耦合头，分类和定位分支共享参数，而FCOS和YOLOX的检测头将两个分支解耦，并在每个分支中额外引入两个3×3卷积层来提高性能。在YOLOv6中，我们采用了一种混合信道策略来构建一个更有效的解耦头。具体来说，我们将中间的3个3×3卷积层的数量减少到只有一个。头部的宽度由主干和颈部的宽度乘数共同缩放。这些修改进一步降低了计算成本，以实现更低的推理延迟。 </p>
<p>​    <strong>Achor-free：</strong> Achor-free检测头因其更好的泛化能力和解码预测结果的简单性而脱颖而出。其后处理的时间成本大大降低了。无锚点探测器有两种类型的无锚点检测器：基于锚点的和基于关键点的。<strong>在YOLOv6中，我们采用了基于锚点的范式，其框回归分支实际上预测了从锚点到边界框四边的距离。</strong></p>
<h3 id="Label-Assignment"><a href="#Label-Assignment" class="headerlink" title="Label Assignment"></a>Label Assignment</h3><p>​    标签分配负责在训练阶段为预定义的锚点分配标签。先前的工作提出了各种标签分配策略，从简单的基于iou的策略和内部地面真值方法到其他更复杂的方案。</p>
<p>​    <strong>SimOTA</strong> OTA认为目标检测中的标签分配是一个最优的传输问题。它从全局的角度为每个地面真实对象定义了正/负的训练样本。SimOTA是OTA的一个简化版本，它减少了额外的超参数并保持了性能。在YOLOv6的早期版本中，使用了SimOTA作为标签分配方法。然而，在实践中，<strong>我们发现引入SimOTA会减慢培训过程。而且经常陷入不稳定的训练。因此，我们希望有一个替代SimOTA。</strong> </p>
<p>​    <strong>Task alignment learning</strong> 任务对齐学习（TAL）首次在TOOD中提出，其中设计了一个统一的分类分数和预测框质量的统一度量。用此度量替换IoU以分配对象标签。在一定程度上，缓解了任务（分类和预测框回归）的错位问题。TOOD的另一个主要贡献是关于任务状头（T-head）。T-head堆栈卷积层来构建交互式特性，在此之上使用了任务对齐预测器（TAP）。PP-YOLOE用轻量级ESE注意取代T-head的层注意，形成ET-head。<strong>然而，我们发现ET-head会恶化我们模型的推理速度，它没有精度增益。因此，我们保留了我们的高效解耦头的设计。</strong></p>
<p>​    <strong>此外，我们观察到TAL比SimOTA带来更多的性能改善，稳定训练。因此，我们在YOLOv6中采用TAL作为默认的标签分配策略。</strong></p>
<h3 id="Loss-Functions"><a href="#Loss-Functions" class="headerlink" title="Loss Functions"></a>Loss Functions</h3><p>​    对象检测包含两个子任务：分类和定位，对应于两个损失函数：分类损失和预测框回归损失。对于每个子任务，近年来都有各种不同的损失函数。在本节中，我们将介绍这些损失函数，并描述我们如何为YOLOv6选择最佳的损失函数。 </p>
<h4 id="Classifification-Loss"><a href="#Classifification-Loss" class="headerlink" title="Classifification Loss"></a><strong>Classifification Loss</strong></h4><p>​     提高分类器的性能是优化检测器的关键部分。Focal Loss改进了传统的交叉熵损失，解决了正负样本或硬易样本之间的类不平衡问题。为了解决训练和推理之间质量估计和分类使用不一致的问题，Quality Focal Loss（QFL）进一步扩展了Focal Loss，并将分类评分和定位质量联合表示出来进行分类监督。<strong>而VariFocal Loss (VFL)来源于Focal Loss，但它不对称地处理正样本和负样本。通过考虑不同重要程度的正样本和负样本，它平衡了来自两个样本的学习信号。Poly Loss将常用的分类损失分解为一系列加权多项式基。它在不同的任务和数据集上调整多项式系数，通过实验证明了其优于交叉熵损失和焦点损失。</strong></p>
<p>​    我们评估了YOLOv6上的所有这些高级分类损失，并最终采用了VFL 。</p>
<h4 id="Box-Regression-Loss"><a href="#Box-Regression-Loss" class="headerlink" title="Box Regression Loss"></a>Box Regression Loss</h4><p>​    预测框回归损失提供了重要的学习信号精确的定位边界框。L1损失是早期工作中原始的预测框回归损失。逐渐地，各种设计良好的预测框回归损失已经出现，如iou系列损失和概率损失。</p>
<p>​    <strong>IoU-series Loss</strong> IoU损失回归了一个预测框作为一个整体单位的四个边界。由于它与评价度量的一致性，它已被证明是有效的。IoU有许多变体，如GIoU、DIoU、CIoU、α-IoU和SIoU等，形成了相关的损失函数。我们用GIoU、CIoU和SIoU进行了实验。而SIOU应用于YOLOv6-N和YOLOv6-T，而其他的则使用GIoU。</p>
<p>​    <strong>Probability Loss</strong>  Distribution Focal Loss<strong>（DFL）将预测框位置的基本连续分布简化为一个离散的概率分布。</strong>它在不引入任何其他强先验的情况下考虑数据中的模糊性和不确定性，有助于提高<strong>预测框</strong>的定位精度，特别是在地面-真值盒的边界模糊的情况下。在DFL的基础上，DFLv2 开发了一个轻量级的子网络，以利用分布统计数据与真实定位质量之间的密切相关性，进一步提高了检测性能。<strong>然而，DFL通常比一般的预测框回归多输出17×的回归值，这导致了大量的开销。额外的计算成本明显地阻碍了对小模型的训练。而DFLv2则由于额外的子网络而进一步增加了计算负担。</strong>在我们的实验中，DFLv2在我们的模型上带来了与DFL相似的性能增益。因此，我们只在YOLOv6-M/L中采用DFL。实验细节见第3.3.3节。</p>
<h4 id="Object-Loss"><a href="#Object-Loss" class="headerlink" title="Object Loss"></a><strong>Object Loss</strong></h4><p>​    Object loss首先是在FCOS中提出的，以降低低质量的边界框的得分，以便在后处理中可以过滤掉它们。它也被用于YOLOX来加速收敛和提高网络精度。作为像FCOS和YOLOX这样的无锚框架，我们尝试在YOLOv6中使用ObjectLoss。不幸的是，它并没有带来许多积极的影响。</p>
<h3 id="Industry-handy-improvements"><a href="#Industry-handy-improvements" class="headerlink" title="Industry-handy improvements"></a>Industry-handy improvements</h3><h4 id="More-training-epochs"><a href="#More-training-epochs" class="headerlink" title="More training epochs"></a><strong>More training epochs</strong></h4><p>​    实验结果表明，训练时间越长，探测器就具有进步的性能。<strong>我们将训练从300个epochs延长到400个epochs，以达到更好的收敛性。</strong></p>
<h4 id="Self-distillation"><a href="#Self-distillation" class="headerlink" title="Self-distillation"></a><strong>Self-distillation</strong></h4><p>​    为了进一步提高模型的准确性，同时不引入太多额外的计算成本，<strong>我们采用经典的知识蒸馏技术来最小化教师模型和学生模型之间预测的KL散度。</strong>我们限制教师模型是预先训练的学生模型，因此我们称之为自我蒸馏。请注意，kl-散度通常用于度量数据分布之间的差异。然而，在目标检测中有两个子任务，其中只有分类任务可以直接利用基于kl-散度的知识精馏。由于DFL损失[20]，我们也可以在预测框回归上执行它。知识蒸馏损失可以表述为： </p>
<p><img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/9ef8cfa56b40480e94f5ce1b36eb5875.png" alt="img"></p>
<p>​    其中<img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/70e48551855e4598af43ca460c462046.png" alt="img">和<img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/956c6028740d47c398f7ef336d6e5ffb.png" alt="img">分别为教师模型和学生模型的类别预测，因此<img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/2421a4e7d6da4247af9d11f7fefe46dc.png" alt="img">和<img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/7628f443735a4c1e9c0a75518ea107e7.png" alt="img">为预测框回归预测。总体损失函数现在可以表述为： </p>
<p><img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/1879de4162f44bb080647818d6350ce4.png" alt="img"></p>
<p>​    其中，Ldet是用预测和标签计算出的检测损失。引入超参数α来平衡两个损失。在训练的早期阶段，从教师模型那里得到的软标签更容易学习。随着训练的继续，学生模型的表现将与教师模型相匹配，这样硬标签将对学生更有帮助。在此基础上，我们将余弦权值衰减应用于α，以动态调整来自教师的硬标签和软标签的信息。</p>
<h4 id="Gray-border-of-images"><a href="#Gray-border-of-images" class="headerlink" title="Gray border of images"></a><strong>Gray border of images</strong></h4><p>​    我们注意到，<strong>在评估YOLOv5 和YOLOv7 实现中的模型性能时，在每个图像周围都设置了一个半步幅的灰色边界。</strong>虽然没有添加任何有用的信息，但它有助于检测图像边缘附近的物体。这个技巧也适用于YOLOv6。 <strong>然而，额外的灰度像素明显降低了推理速度。如果没有灰色边框，YOLOv6的性能就会恶化</strong>。我们假设该问题与Mosaic augmentation中的灰色边界填充有关。实验在关闭mosaic增强在最后的epochs进行验证。在这方面，我们改变了灰度边界的面积，并将具有灰度边界的图像的大小直接调整为目标图像的大小。结合这两种策略，我们的模型可以保持甚至提高性能，而不降低推理速度。</p>
<h3 id="Quantization-and-Deployment"><a href="#Quantization-and-Deployment" class="headerlink" title="Quantization and Deployment"></a><strong>Quantization and Deployment</strong></h3><p>​    对于工业部署，通常的做法是采用量化以进一步加快运行时，而不会影响太多性能。训练后量化（PTQ）直接用一个小的校准集对模型进行量化。而量化感知训练（QAT）进一步提高了对训练集的访问的性能，这通常与蒸馏联合使用。<strong>然而，由于在YOLOv6中大量使用重新参数化块，以前的PTQ技术不能产生高性能，而在训练和推理过程中匹配假量化器时，很难合并QAT。</strong>我们在这里展示了在部署期间的陷阱和我们的解决方法。 </p>
<h4 id="Reparameterizing-Optimizer"><a href="#Reparameterizing-Optimizer" class="headerlink" title="Reparameterizing Optimizer"></a><strong>Reparameterizing Optimizer</strong></h4><p>​    RepOptimizer<strong>在每个优化步骤中提出梯度重新参数化。</strong>该技术也能很好地解决了基于再参数化的模型的量化问题。因此，我们以这种方式重建了YOLOv6的重新参数化块，并使用重新优化器对其进行训练，以获得对PTQ友好的权值。特征图的分布很窄，这大大有利于量化过程。 </p>
<p><img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/408b78b8e84d40c590319c35205855c0.png" alt="img"></p>
<h4 id="Sensitivity-Analysis"><a href="#Sensitivity-Analysis" class="headerlink" title="Sensitivity Analysis"></a><strong>Sensitivity Analysis</strong></h4><p>​    我们通过将量化敏感操作部分转换为浮点计算，进一步提高了PTQ的性能。为了获得灵敏度分布，我们常用了几个指标，即均方误差（MSE）、信噪比（SNR）和余弦相似度。通常，为了进行比较，可以选择输出特征映射（在激活某一层之后）来计算有量化和没有量化的这些度量。作为一种替代方法，它也可以通过开关特定层的量化来计算验证AP。</p>
<p>​    我们在使用重新优化器训练的YOLOv6-S模型上计算所有这些指标，并选择前6个敏感层，以浮动形式运行。敏感性分析的完整图表见B.2。</p>
<p><img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/88873d7d91d945c79f54014e725fbe13.png" alt="img"> </p>
<h4 id="Quantization-aware-Training-with-Channel-wise-Distillation"><a href="#Quantization-aware-Training-with-Channel-wise-Distillation" class="headerlink" title="Quantization-aware Training with Channel-wise Distillation"></a><strong>Quantization-aware Training with Channel-wise</strong> <strong>Distillation</strong></h4><p>​    <strong>在PTQ不足的情况下，我们建议涉及量化感知训练（QAT）来提高量化性能。为了解决在训练和推理过程中假量化器的不一致性问题，有必要在重新优化器上建立QAT。</strong>此外，在YOLOv6框架内采用了通道蒸馏（后来称为CW蒸馏），如图5所示。这也是一种自蒸馏的方法，其中教师网络是在fp32精度上的学生模型。参见第3.5.1节中的实验。 </p>
<p><img src="/2023/06/18/YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications/cda38d2ac2884096b174b6dc66edbb6e-168707903752712.png" alt="cda38d2ac2884096b174b6dc66edbb6e"></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/06/18/RepVGG-Making-VGG-style-ConvNets-Great-Again/" rel="prev" title="RepVGG Making VGG-style ConvNets Great Again">
      <i class="fa fa-chevron-left"></i> RepVGG Making VGG-style ConvNets Great Again
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/06/18/YOLOv7-Trainable-bag-of-freebies-sets-new-state-of-the-art-for-real-time-object-detectors/" rel="next" title="YOLOv7 Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors">
      YOLOv7 Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#YOLOv6-A-Single-Stage-Object-Detection-Framework-for-Industrial-Applications"><span class="nav-number">1.</span> <span class="nav-text">YOLOv6: A Single-Stage Object Detection Framework for Industrial  Applications</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLOv6%E5%8F%91%E7%8E%B0%E4%BB%A5%E5%BE%80%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%9C%A8%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A"><span class="nav-number">1.1.</span> <span class="nav-text">YOLOv6发现以往的模型存在以下问题：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%AC%E6%96%87%E7%9A%84%E4%B8%BB%E8%A6%81%E5%B7%A5%E4%BD%9C"><span class="nav-number">1.2.</span> <span class="nav-text">本文的主要工作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E7%9A%84%E6%96%B9%E6%B3%95-amp-%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B7%E4%BD%93%E7%BB%93%E6%9E%84"><span class="nav-number">1.3.</span> <span class="nav-text">使用的方法&amp;模型的具体结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Network-Design"><span class="nav-number">1.4.</span> <span class="nav-text">Network Design</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Backbone"><span class="nav-number">1.4.1.</span> <span class="nav-text">Backbone</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neck"><span class="nav-number">1.4.2.</span> <span class="nav-text">Neck</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Head"><span class="nav-number">1.4.3.</span> <span class="nav-text">Head</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Label-Assignment"><span class="nav-number">1.4.4.</span> <span class="nav-text">Label Assignment</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Loss-Functions"><span class="nav-number">1.4.5.</span> <span class="nav-text">Loss Functions</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Classifification-Loss"><span class="nav-number">1.4.5.1.</span> <span class="nav-text">Classifification Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Box-Regression-Loss"><span class="nav-number">1.4.5.2.</span> <span class="nav-text">Box Regression Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Object-Loss"><span class="nav-number">1.4.5.3.</span> <span class="nav-text">Object Loss</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Industry-handy-improvements"><span class="nav-number">1.4.6.</span> <span class="nav-text">Industry-handy improvements</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#More-training-epochs"><span class="nav-number">1.4.6.1.</span> <span class="nav-text">More training epochs</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Self-distillation"><span class="nav-number">1.4.6.2.</span> <span class="nav-text">Self-distillation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Gray-border-of-images"><span class="nav-number">1.4.6.3.</span> <span class="nav-text">Gray border of images</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Quantization-and-Deployment"><span class="nav-number">1.4.7.</span> <span class="nav-text">Quantization and Deployment</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Reparameterizing-Optimizer"><span class="nav-number">1.4.7.1.</span> <span class="nav-text">Reparameterizing Optimizer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sensitivity-Analysis"><span class="nav-number">1.4.7.2.</span> <span class="nav-text">Sensitivity Analysis</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Quantization-aware-Training-with-Channel-wise-Distillation"><span class="nav-number">1.4.7.3.</span> <span class="nav-text">Quantization-aware Training with Channel-wise Distillation</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">凯</p>
  <div class="site-description" itemprop="description">选择大于努力</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">凯</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
