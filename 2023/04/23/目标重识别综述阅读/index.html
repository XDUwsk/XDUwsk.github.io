<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="目标重识别论文阅读笔记Deep Learning for Person Re-identification: A Survey and Outlook定义：行人重识别（以下简称reid）问题是在没有重叠场景的摄像机拍摄画面下，对目标行人进行检索。 现阶段的reid问题主要分为两大类：closed-world和open-world。说人话就是，closed-world重在研究，在各种面向研究的假设的">
<meta property="og:type" content="article">
<meta property="og:title" content="目标重识别综述阅读">
<meta property="og:url" content="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/index.html">
<meta property="og:site_name" content="凯_kaiii">
<meta property="og:description" content="目标重识别论文阅读笔记Deep Learning for Person Re-identification: A Survey and Outlook定义：行人重识别（以下简称reid）问题是在没有重叠场景的摄像机拍摄画面下，对目标行人进行检索。 现阶段的reid问题主要分为两大类：closed-world和open-world。说人话就是，closed-world重在研究，在各种面向研究的假设的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQmFsYWJvbw==,size_20,color_FFFFFF,t_70,g_se,x_16.png">
<meta property="og:image" content="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/image-20230309134909484.png">
<meta property="og:image" content="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/image-20230309135813177.png">
<meta property="og:image" content="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/20200710212437448.png">
<meta property="og:image" content="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/202007102124402.png">
<meta property="og:image" content="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/20200710212501363.png">
<meta property="og:image" content="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/2020071021245875.png">
<meta property="og:image" content="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQmFsYWJvbw==,size_20,color_FFFFFF,t_70,g_se,x_16-16783434167663.png">
<meta property="article:published_time" content="2023-04-23T11:48:09.000Z">
<meta property="article:modified_time" content="2023-04-23T12:57:28.275Z">
<meta property="article:author" content="凯">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQmFsYWJvbw==,size_20,color_FFFFFF,t_70,g_se,x_16.png">

<link rel="canonical" href="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>目标重识别综述阅读 | 凯_kaiii</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">凯_kaiii</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">暂无</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="凯">
      <meta itemprop="description" content="选择大于努力">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="凯_kaiii">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          目标重识别综述阅读
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-04-23 19:48:09 / 修改时间：20:57:28" itemprop="dateCreated datePublished" datetime="2023-04-23T19:48:09+08:00">2023-04-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="目标重识别论文阅读笔记"><a href="#目标重识别论文阅读笔记" class="headerlink" title="目标重识别论文阅读笔记"></a>目标重识别论文阅读笔记</h1><h2 id="Deep-Learning-for-Person-Re-identification-A-Survey-and-Outlook"><a href="#Deep-Learning-for-Person-Re-identification-A-Survey-and-Outlook" class="headerlink" title="Deep Learning for Person Re-identification: A Survey and Outlook"></a>Deep Learning for Person Re-identification: A Survey and Outlook</h2><h3 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h3><p>行人重识别（以下简称reid）问题是在没有重叠场景的摄像机拍摄画面下，对目标行人进行检索。</p>
<p>现阶段的reid问题主要分为两大类：closed-world和open-world。说人话就是，closed-world重在研究，在各种面向研究的假设的基础上进行研究，主要是从一大堆行人的bounding box图片中去检索目标行人，而open-world重在“落地”，主要是直接从视频中去检索目标行人，或者是偏向无监督、弱监督学习。</p>
<h3 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h3><p><strong>不同视角、参差不齐的低分辨率图像、光照变化、姿态不同、遮挡情况、异构数据、复杂的相机环境、背景环境、不可靠的边缘框生成</strong>都会对ReID任务造成影响和挑战。实际部署时，摄像头的变化、Gallery十分巨大、数据要求高、对网络的泛化能力要求高、外表特征的变化等也是影响很大的因素。</p>
<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li><strong>原始数据收集</strong>：从处于不同环境的不同地方的摄像机获取原始视频数据。这些数据包含大量的背景杂波。</li>
<li><strong>边界框（Bounding Box）生成</strong>：通过行人检测或跟踪算法从原始视频数据中提取包含行人图像的边界框。在大规模应用中不可能手动裁剪所有行人图像。</li>
<li><strong>训练数据标注</strong>：对于区分行人任务来说，图像标注必不可少。</li>
<li><strong>模型构建和训练</strong>：已经开发了广泛运用的模型，重点在于特征表示学习、度量学习或两者结合。</li>
<li><strong>测试阶段</strong>：给定一个query和一组gallery，使用上一阶段训练完毕的模型进行行人特征提取，计算query图像和gallery图像的相似度进行排序。</li>
</ol>
<p><img src="/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQmFsYWJvbw==,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="img"></p>
<p>即closed-world和open-world ReID之间的区别可总结如下：</p>
<ul>
<li><strong>单模态和异构数据</strong></li>
<li><strong>边界框生成和原始图像/视频</strong></li>
<li><strong>丰富的标签数据和不可用/有限的标签</strong></li>
<li><strong>正确标签和噪声标签</strong></li>
<li><strong>query是否存在于gallery中</strong></li>
</ul>
<h3 id="closed-world-ReID介绍以及方法总览"><a href="#closed-world-ReID介绍以及方法总览" class="headerlink" title="closed-world ReID介绍以及方法总览"></a>closed-world ReID介绍以及方法总览</h3><h4 id="closed-wrold假设"><a href="#closed-wrold假设" class="headerlink" title="closed-wrold假设"></a>closed-wrold假设</h4><ul>
<li>通过单模态可见光摄像机捕获行人</li>
<li>已经给出行人bounding box</li>
<li>有足够的标注好的训练数据。用于监督训练</li>
<li>标签通常是正确的</li>
<li>query行人必须出现在图库中</li>
</ul>
<h4 id="特征表示学习"><a href="#特征表示学习" class="headerlink" title="特征表示学习"></a>特征表示学习</h4><h4 id="全局表征学习"><a href="#全局表征学习" class="headerlink" title="全局表征学习"></a>全局表征学习</h4><p>从每个人的图像中提取特征向量，直接将行人图片送入网络进行特征的提取。</p>
<h4 id="局部表征学习"><a href="#局部表征学习" class="headerlink" title="局部表征学习"></a>局部表征学习</h4><p>将行人的图片进行分块，使用网络对每一个块进行特征提取，最后将所有的特征结合起来</p>
<h4 id="辅助表征学习"><a href="#辅助表征学习" class="headerlink" title="辅助表征学习"></a>辅助表征学习</h4><p>在网络中加入一些辅助性对目标进行描述的元素，例如外观描述，视角描述、区域信息等。</p>
<h4 id="基于视频的表征学习"><a href="#基于视频的表征学习" class="headerlink" title="基于视频的表征学习"></a>基于视频的表征学习</h4><p>输入为由多张图片组成的行人的视频序列，其具有丰富的外表和时域信息。</p>
<p><img src="/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/image-20230309134909484.png" alt="image-20230309134909484"></p>
<h4 id="度量学习"><a href="#度量学习" class="headerlink" title="度量学习"></a>度量学习</h4><p>度量学习目前的主要工作集中以及体现于特征学习中的loss函数的设计，目前最常用的三种loss为：<strong>identity loss</strong>、<strong>verification loss</strong>、<strong>triplet loss</strong>以及其的变种。</p>
<p><img src="/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/image-20230309135813177.png" alt="image-20230309135813177" style="zoom:50%;"></p>
<h5 id="identity-loss"><a href="#identity-loss" class="headerlink" title="identity loss"></a>identity loss</h5><p>将行人重识别的训练过程视为图像分类问题，将每个人视作一个独立的类别，通过类比于图像分类的方式进行重识别。这种方式其在训练过程中能较为容易训练和自动挖掘困难样本</p>
<p><img src="/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/20200710212437448.png" alt="在这里插入图片描述"></p>
<h5 id="verification-loss"><a href="#verification-loss" class="headerlink" title="verification loss"></a>verification loss</h5><p>用对比损失函数或者二元损失函数来优化成对样本间关联。对比损失函数提升了成对样本距离比较，即为学习使不同类别的图像对应的特征相距较远</p>
<p><img src="/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/202007102124402.png" alt="在这里插入图片描述"></p>
<p>或</p>
<p><img src="/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/20200710212501363.png" alt="在这里插入图片描述"></p>
<h5 id="triplet-loss"><a href="#triplet-loss" class="headerlink" title="triplet loss"></a>triplet loss</h5><p>将ReID问题看作是检索排序问题，其主要思想可以看作同一个样本之间的距离应该小于不同的样本之间的距离</p>
<p><img src="/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/2020071021245875.png" alt="在这里插入图片描述"></p>
<h4 id="数据集和评价指标"><a href="#数据集和评价指标" class="headerlink" title="数据集和评价指标"></a>数据集和评价指标</h4><p><img src="/2023/04/23/%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQmFsYWJvbw==,size_20,color_FFFFFF,t_70,g_se,x_16-16783434167663.png" alt="img"></p>
<h4 id="SOTA-方法解析"><a href="#SOTA-方法解析" class="headerlink" title="SOTA 方法解析"></a>SOTA 方法解析</h4><h5 id="基于图像的ReID"><a href="#基于图像的ReID" class="headerlink" title="基于图像的ReID"></a>基于图像的ReID</h5><h6 id="VAL：引入视角信息"><a href="#VAL：引入视角信息" class="headerlink" title="VAL：引入视角信息"></a>VAL：引入视角信息</h6><p>目前通过神经网络的目标重识别的识别能力已经高于人工辨识的准确度，sota数据中常常使用目标的全局特征结合局部特征进行融合，从而达到更好的效果</p>
<p>文章强调注意力机制的有效性，多损失训练的有效性</p>
<h5 id="基于视频的ReID"><a href="#基于视频的ReID" class="headerlink" title="基于视频的ReID"></a>基于视频的ReID</h5><p>时空建模对提取视频特征是十分重要的，其中包含跨多帧的注意力机制，甚至利用视频序列中的多帧可以填补被遮挡的部份。</p>
<h3 id="Open-world-ReID"><a href="#Open-world-ReID" class="headerlink" title="Open-world ReID"></a>Open-world ReID</h3><h5 id="Depth-based-Re-ID：捕获人体形状和骨骼状态，提供在光照差别大、换衣服情况下的重识别的解决方案。"><a href="#Depth-based-Re-ID：捕获人体形状和骨骼状态，提供在光照差别大、换衣服情况下的重识别的解决方案。" class="headerlink" title="Depth-based Re-ID：捕获人体形状和骨骼状态，提供在光照差别大、换衣服情况下的重识别的解决方案。"></a>Depth-based Re-ID：捕获人体形状和骨骼状态，提供在光照差别大、换衣服情况下的重识别的解决方案。</h5><h5 id="Text-To-Image-ReID：解决在语言描述和RGB图像之间的匹配上的问题，用一段语言描述来代替对目标的文字描述"><a href="#Text-To-Image-ReID：解决在语言描述和RGB图像之间的匹配上的问题，用一段语言描述来代替对目标的文字描述" class="headerlink" title="Text-To-Image ReID：解决在语言描述和RGB图像之间的匹配上的问题，用一段语言描述来代替对目标的文字描述"></a>Text-To-Image ReID：解决在语言描述和RGB图像之间的匹配上的问题，用一段语言描述来代替对目标的文字描述</h5><h5 id="Visible-Infrared-Re-ID：处理在白天可视化图片和夜晚红外图片之间的跨模态匹配问题，解决低光照问题"><a href="#Visible-Infrared-Re-ID：处理在白天可视化图片和夜晚红外图片之间的跨模态匹配问题，解决低光照问题" class="headerlink" title="Visible-Infrared Re-ID：处理在白天可视化图片和夜晚红外图片之间的跨模态匹配问题，解决低光照问题"></a>Visible-Infrared Re-ID：处理在白天可视化图片和夜晚红外图片之间的跨模态匹配问题，解决低光照问题</h5><h5 id="Cross-Resolution-Re-ID：跨分辨率的ReID在低分辨率图片和高分辨率图片中进行匹配，处理大分辨率的变化问题"><a href="#Cross-Resolution-Re-ID：跨分辨率的ReID在低分辨率图片和高分辨率图片中进行匹配，处理大分辨率的变化问题" class="headerlink" title="Cross-Resolution Re-ID：跨分辨率的ReID在低分辨率图片和高分辨率图片中进行匹配，处理大分辨率的变化问题"></a>Cross-Resolution Re-ID：跨分辨率的ReID在低分辨率图片和高分辨率图片中进行匹配，处理大分辨率的变化问题</h5><h4 id="End-to-End-ReID"><a href="#End-to-End-ReID" class="headerlink" title="End-to-End ReID"></a>End-to-End ReID</h4><p>端到端的ReID减缓了对边缘框的需求问题，直接利用原始的视频信息、图像信息进行计算，得出对应的目标ID在视频中的位置</p>
<h4 id="ReID-in-Raw-Images-Videos"><a href="#ReID-in-Raw-Images-Videos" class="headerlink" title="ReID in Raw Images/Videos"></a>ReID in Raw Images/Videos</h4><p>该任务需要同一个模型同时完成人物检测和ReID任务，由于两个主要部件的侧重点有所不同，所以是一个有挑战性的任务</p>
<h4 id="Multi-camera-Tracking"><a href="#Multi-camera-Tracking" class="headerlink" title="Multi-camera Tracking"></a>Multi-camera Tracking</h4><p>该任务与MTMCT（multi-person, multi-camera tracking）近似，可根据基于图的连接、多目标多摄像机跟踪与重识别之间的相关性进行优化解决。</p>
<h4 id="Semi-supervised-and-Unsupervised-Re-ID"><a href="#Semi-supervised-and-Unsupervised-Re-ID" class="headerlink" title="Semi-supervised and Unsupervised Re-ID"></a>Semi-supervised and Unsupervised Re-ID</h4><h4 id="Noise-Robust-Re-ID"><a href="#Noise-Robust-Re-ID" class="headerlink" title="Noise-Robust Re-ID"></a>Noise-Robust Re-ID</h4><h4 id="Open-set-Re-ID-and-Beyond"><a href="#Open-set-Re-ID-and-Beyond" class="headerlink" title="Open-set Re-ID and Beyond"></a>Open-set Re-ID and Beyond</h4><p>Open-set ReID通常被视为目标验证问题，辨别两个人员图像是否属于同一个目标。对于该问题，Adversarial PersonNet (APN) 共同学习GAN模块和Re-ID特征提取器。然而该问题依旧有非常大的提升空间，例如更高的识别率和更低的错误率。</p>
<h5 id="Re-ID组"><a href="#Re-ID组" class="headerlink" title="Re-ID组"></a>Re-ID组</h5><p>它的目的是将人以群体而不是个人的形式联系起来。早期的研究主要集中在利用稀疏字典学习或协方差描述子聚集进行组表示提取。最近，应用图卷积网络，将群表示为图。在端到端人搜索和个体再识别中也应用了群体相似性来提高准确性。然而，群体Re-ID仍然具有挑战性，因为群体变异比个体更复杂。</p>
<h5 id="动态多摄像机网络"><a href="#动态多摄像机网络" class="headerlink" title="动态多摄像机网络"></a>动态多摄像机网络</h5><p>动态更新多摄像机网络是另一个具有挑战性的问题，需要对新的摄像机或探头进行模型适配。引入一种人在循环增量学习方法来更新Re-ID模型，适应不同探测库的表示。早期的研究也将主动学习应用于多摄像头网络的连续Re-ID。引入了一种基于稀疏非冗余代表选择的连续自适应方法。设计了一种传递推理算法来开发基于测地线流核的最佳源摄像机模型。密集人群和社会关系中的多种环境约束(如摄像机拓扑)被集成到开放世界的人Re-ID系统中。在实际的动态多摄像机网络中，摄像机的模型自适应和环境因素是至关重要的。此外，如何将深度学习技术应用于动态多摄像机网络的研究还较少。</p>
<h3 id="对ReID技术的总览和展望"><a href="#对ReID技术的总览和展望" class="headerlink" title="对ReID技术的总览和展望"></a>对ReID技术的总览和展望</h3><h4 id="mINP-A-New-Evaluation-Metric-for-Re-ID"><a href="#mINP-A-New-Evaluation-Metric-for-Re-ID" class="headerlink" title="mINP: A New Evaluation Metric for Re-ID"></a>mINP: A New Evaluation Metric for Re-ID</h4><h4 id="单-跨模态重新识别的新基线-AGW"><a href="#单-跨模态重新识别的新基线-AGW" class="headerlink" title="单/跨模态重新识别的新基线 AGW"></a>单/跨模态重新识别的新基线 AGW</h4><h4 id="尚未调查的未决问题"><a href="#尚未调查的未决问题" class="headerlink" title="尚未调查的未决问题"></a>尚未调查的未决问题</h4><p>Open-set Re-ID、overlapping camera、same time、based on video </p>
<h2 id="Person-Re-identification-A-Retrospective-on-Domain-Specific"><a href="#Person-Re-identification-A-Retrospective-on-Domain-Specific" class="headerlink" title="Person Re-identification A Retrospective on Domain Specific"></a>Person Re-identification A Retrospective on Domain Specific</h2><p>Re-ID的应用场景：智能视频监控、机器人、人机交互、自动视觉监视系统等</p>
<p>Re-ID遇到的问题：遮挡、位姿方差、背景杂波、不对中、尺度差异、照明方差、视点方差、低分辨率和跨域或泛化。</p>
<p>该文从遮挡、位姿方差、背景杂波等六个方面总结了在该领域上做得最好的CNN、Attention、Self-Attention的论文。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/04/12/c-%E4%B8%AD%E7%9A%84ffmpeg%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/" rel="prev" title="c++中的ffmpeg源码学习">
      <i class="fa fa-chevron-left"></i> c++中的ffmpeg源码学习
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/04/23/Bag%20of%20Tricks%20and%20A%20Strong%20Baseline%20for%20Deep%20Person%20Re-identification.md/" rel="next" title="Bag of Tricks and A Strong Baseline for Deep Person Re-identification">
      Bag of Tricks and A Strong Baseline for Deep Person Re-identification <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E9%87%8D%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0"><span class="nav-number">1.</span> <span class="nav-text">目标重识别论文阅读笔记</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-Learning-for-Person-Re-identification-A-Survey-and-Outlook"><span class="nav-number">1.1.</span> <span class="nav-text">Deep Learning for Person Re-identification: A Survey and Outlook</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%EF%BC%9A"><span class="nav-number">1.1.1.</span> <span class="nav-text">定义：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%BE%E7%82%B9"><span class="nav-number">1.1.2.</span> <span class="nav-text">难点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A5%E9%AA%A4"><span class="nav-number">1.1.3.</span> <span class="nav-text">步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#closed-world-ReID%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E6%96%B9%E6%B3%95%E6%80%BB%E8%A7%88"><span class="nav-number">1.1.4.</span> <span class="nav-text">closed-world ReID介绍以及方法总览</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#closed-wrold%E5%81%87%E8%AE%BE"><span class="nav-number">1.1.4.1.</span> <span class="nav-text">closed-wrold假设</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.1.4.2.</span> <span class="nav-text">特征表示学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.1.4.3.</span> <span class="nav-text">全局表征学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B1%80%E9%83%A8%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.1.4.4.</span> <span class="nav-text">局部表征学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BE%85%E5%8A%A9%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.1.4.5.</span> <span class="nav-text">辅助表征学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E8%A7%86%E9%A2%91%E7%9A%84%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.1.4.6.</span> <span class="nav-text">基于视频的表征学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.1.4.7.</span> <span class="nav-text">度量学习</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#identity-loss"><span class="nav-number">1.1.4.7.1.</span> <span class="nav-text">identity loss</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#verification-loss"><span class="nav-number">1.1.4.7.2.</span> <span class="nav-text">verification loss</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#triplet-loss"><span class="nav-number">1.1.4.7.3.</span> <span class="nav-text">triplet loss</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="nav-number">1.1.4.8.</span> <span class="nav-text">数据集和评价指标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SOTA-%E6%96%B9%E6%B3%95%E8%A7%A3%E6%9E%90"><span class="nav-number">1.1.4.9.</span> <span class="nav-text">SOTA 方法解析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E7%9A%84ReID"><span class="nav-number">1.1.4.9.1.</span> <span class="nav-text">基于图像的ReID</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#VAL%EF%BC%9A%E5%BC%95%E5%85%A5%E8%A7%86%E8%A7%92%E4%BF%A1%E6%81%AF"><span class="nav-number">1.1.4.9.1.1.</span> <span class="nav-text">VAL：引入视角信息</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E8%A7%86%E9%A2%91%E7%9A%84ReID"><span class="nav-number">1.1.4.9.2.</span> <span class="nav-text">基于视频的ReID</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Open-world-ReID"><span class="nav-number">1.1.5.</span> <span class="nav-text">Open-world ReID</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Depth-based-Re-ID%EF%BC%9A%E6%8D%95%E8%8E%B7%E4%BA%BA%E4%BD%93%E5%BD%A2%E7%8A%B6%E5%92%8C%E9%AA%A8%E9%AA%BC%E7%8A%B6%E6%80%81%EF%BC%8C%E6%8F%90%E4%BE%9B%E5%9C%A8%E5%85%89%E7%85%A7%E5%B7%AE%E5%88%AB%E5%A4%A7%E3%80%81%E6%8D%A2%E8%A1%A3%E6%9C%8D%E6%83%85%E5%86%B5%E4%B8%8B%E7%9A%84%E9%87%8D%E8%AF%86%E5%88%AB%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%82"><span class="nav-number">1.1.5.0.1.</span> <span class="nav-text">Depth-based Re-ID：捕获人体形状和骨骼状态，提供在光照差别大、换衣服情况下的重识别的解决方案。</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Text-To-Image-ReID%EF%BC%9A%E8%A7%A3%E5%86%B3%E5%9C%A8%E8%AF%AD%E8%A8%80%E6%8F%8F%E8%BF%B0%E5%92%8CRGB%E5%9B%BE%E5%83%8F%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%B9%E9%85%8D%E4%B8%8A%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%8C%E7%94%A8%E4%B8%80%E6%AE%B5%E8%AF%AD%E8%A8%80%E6%8F%8F%E8%BF%B0%E6%9D%A5%E4%BB%A3%E6%9B%BF%E5%AF%B9%E7%9B%AE%E6%A0%87%E7%9A%84%E6%96%87%E5%AD%97%E6%8F%8F%E8%BF%B0"><span class="nav-number">1.1.5.0.2.</span> <span class="nav-text">Text-To-Image ReID：解决在语言描述和RGB图像之间的匹配上的问题，用一段语言描述来代替对目标的文字描述</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Visible-Infrared-Re-ID%EF%BC%9A%E5%A4%84%E7%90%86%E5%9C%A8%E7%99%BD%E5%A4%A9%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%E7%89%87%E5%92%8C%E5%A4%9C%E6%99%9A%E7%BA%A2%E5%A4%96%E5%9B%BE%E7%89%87%E4%B9%8B%E9%97%B4%E7%9A%84%E8%B7%A8%E6%A8%A1%E6%80%81%E5%8C%B9%E9%85%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E8%A7%A3%E5%86%B3%E4%BD%8E%E5%85%89%E7%85%A7%E9%97%AE%E9%A2%98"><span class="nav-number">1.1.5.0.3.</span> <span class="nav-text">Visible-Infrared Re-ID：处理在白天可视化图片和夜晚红外图片之间的跨模态匹配问题，解决低光照问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Cross-Resolution-Re-ID%EF%BC%9A%E8%B7%A8%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84ReID%E5%9C%A8%E4%BD%8E%E5%88%86%E8%BE%A8%E7%8E%87%E5%9B%BE%E7%89%87%E5%92%8C%E9%AB%98%E5%88%86%E8%BE%A8%E7%8E%87%E5%9B%BE%E7%89%87%E4%B8%AD%E8%BF%9B%E8%A1%8C%E5%8C%B9%E9%85%8D%EF%BC%8C%E5%A4%84%E7%90%86%E5%A4%A7%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84%E5%8F%98%E5%8C%96%E9%97%AE%E9%A2%98"><span class="nav-number">1.1.5.0.4.</span> <span class="nav-text">Cross-Resolution Re-ID：跨分辨率的ReID在低分辨率图片和高分辨率图片中进行匹配，处理大分辨率的变化问题</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#End-to-End-ReID"><span class="nav-number">1.1.5.1.</span> <span class="nav-text">End-to-End ReID</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ReID-in-Raw-Images-Videos"><span class="nav-number">1.1.5.2.</span> <span class="nav-text">ReID in Raw Images&#x2F;Videos</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multi-camera-Tracking"><span class="nav-number">1.1.5.3.</span> <span class="nav-text">Multi-camera Tracking</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Semi-supervised-and-Unsupervised-Re-ID"><span class="nav-number">1.1.5.4.</span> <span class="nav-text">Semi-supervised and Unsupervised Re-ID</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Noise-Robust-Re-ID"><span class="nav-number">1.1.5.5.</span> <span class="nav-text">Noise-Robust Re-ID</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Open-set-Re-ID-and-Beyond"><span class="nav-number">1.1.5.6.</span> <span class="nav-text">Open-set Re-ID and Beyond</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Re-ID%E7%BB%84"><span class="nav-number">1.1.5.6.1.</span> <span class="nav-text">Re-ID组</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E5%A4%9A%E6%91%84%E5%83%8F%E6%9C%BA%E7%BD%91%E7%BB%9C"><span class="nav-number">1.1.5.6.2.</span> <span class="nav-text">动态多摄像机网络</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9ReID%E6%8A%80%E6%9C%AF%E7%9A%84%E6%80%BB%E8%A7%88%E5%92%8C%E5%B1%95%E6%9C%9B"><span class="nav-number">1.1.6.</span> <span class="nav-text">对ReID技术的总览和展望</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#mINP-A-New-Evaluation-Metric-for-Re-ID"><span class="nav-number">1.1.6.1.</span> <span class="nav-text">mINP: A New Evaluation Metric for Re-ID</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%95-%E8%B7%A8%E6%A8%A1%E6%80%81%E9%87%8D%E6%96%B0%E8%AF%86%E5%88%AB%E7%9A%84%E6%96%B0%E5%9F%BA%E7%BA%BF-AGW"><span class="nav-number">1.1.6.2.</span> <span class="nav-text">单&#x2F;跨模态重新识别的新基线 AGW</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%9A%E6%9C%AA%E8%B0%83%E6%9F%A5%E7%9A%84%E6%9C%AA%E5%86%B3%E9%97%AE%E9%A2%98"><span class="nav-number">1.1.6.3.</span> <span class="nav-text">尚未调查的未决问题</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Person-Re-identification-A-Retrospective-on-Domain-Specific"><span class="nav-number">1.2.</span> <span class="nav-text">Person Re-identification A Retrospective on Domain Specific</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">凯</p>
  <div class="site-description" itemprop="description">选择大于努力</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">凯</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
