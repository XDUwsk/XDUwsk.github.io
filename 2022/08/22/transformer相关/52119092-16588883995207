<!doctype html>
<html lang="zh" data-hairline="true" data-theme="light"><head><meta charSet="utf-8"/><title data-rh="true">NLP中的RNN、Seq2Seq与attention注意力机制 - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"/><meta name="renderer" content="webkit"/><meta name="force-rendering" content="webkit"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"/><meta data-rh="true" name="keywords" content="RNN,注意力机制"/><meta data-rh="true" name="description" content="RNN循环神经网络RNN循环神经网络被广泛应用于自然语言处理中，对于处理序列数据有很好的效果，常见的序列数据有文本、语音等，至于为什么要用到循环神经网络而不是传统的神经网络，我们在这里举一个例子。 假如有…"/><meta data-rh="true" property="og:title" content="NLP中的RNN、Seq2Seq与attention注意力机制"/><meta data-rh="true" property="og:url" content="https://zhuanlan.zhihu.com/p/52119092"/><meta data-rh="true" property="og:description" content="RNN循环神经网络RNN循环神经网络被广泛应用于自然语言处理中，对于处理序列数据有很好的效果，常见的序列数据有文本、语音等，至于为什么要用到循环神经网络而不是传统的神经网络，我们在这里举一个例子。 假如有…"/><meta data-rh="true" property="og:image" content="https://pic2.zhimg.com/v2-4f760232b1cd7ab29749948a3656b027_720w.jpg?source=172ae18b"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="og:site_name" content="知乎专栏"/><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.a53ae37b.png"/><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.a53ae37b.png" sizes="152x152"/><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.bbce8f18.png" sizes="120x120"/><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.cbade8f9.png" sizes="76x76"/><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.8f6c52aa.png" sizes="60x60"/><link crossorigin="" rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/heifetz/favicon.ico"/><link crossorigin="" rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/heifetz/search.xml" title="知乎"/><link rel="dns-prefetch" href="//static.zhimg.com"/><link rel="dns-prefetch" href="//pica.zhimg.com"/><link rel="dns-prefetch" href="//pic1.zhimg.com"/><link rel="dns-prefetch" href="//pic2.zhimg.com"/><link rel="dns-prefetch" href="//pic3.zhimg.com"/><link rel="dns-prefetch" href="//pic4.zhimg.com"/><link rel="dns-prefetch" href="//static.zhihu.com"/><style data-emotion-css="1m4merm">.u-safeAreaInset-top{height:constant(safe-area-inset-top) !important;height:env(safe-area-inset-top) !important;}.u-safeAreaInset-bottom{height:constant(safe-area-inset-bottom) !important;height:env(safe-area-inset-bottom) !important;}</style><link href="https://static.zhihu.com/heifetz/column.app.216a26f4.09b2d938a58c06ded7d6.css" crossorigin="" rel="stylesheet"/><script nonce="cb1bd0f8-6fdd-4789-9a81-657226258716">!function(){"use strict";!function(e,n){var r=[];function t(e){return function(){r.push([e,arguments])}}n.Raven={captureException:t("captureException"),captureMessage:t("captureMessage"),captureBreadcrumb:t("captureBreadcrumb")};var a,o,c,i,s,u="undefined"!=typeof DOMError;function d(e){var n=e instanceof Error||e instanceof ErrorEvent||u&&e instanceof DOMError||e instanceof DOMException;Raven.captureException(n?e:new Error(e.message||e.reason))}n.addEventListener("unhandledrejection",d),n.addEventListener("error",d,!0),a=e.src,o=e,c=function(){r.forEach(function(e){var n;(n=Raven)[e[0]].apply(n,e[1])}),n.removeEventListener("unhandledrejection",d),n.removeEventListener("error",d,!0)},i=document.head||document.getElementsByTagName("head")[0],(s=document.createElement("script")).crossOrigin=o.crossOrigin,s.dataset.sentryConfig=o["data-sentry-config"],s.onload=c,s.src=a,i.appendChild(s)}({"defer":true,"crossOrigin":"anonymous","src":"https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js","data-sentry-config":"{\"dsn\":\"https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224\",\"sampleRate\":0.1,\"release\":\"4480-6c6f661d\",\"ignoreErrorNames\":[\"NetworkError\",\"SecurityError\"],\"ignoreErrorsPreset\":\"ReactApp\",\"tags\":{\"app_name\":\"heifetz\"}}"},window)}();
</script></head><body class="WhiteBg-body PostIndex-body"><div id="root"><div class="App"><div class="LoadingBar"></div><div><span style="position:absolute;top:-10000px;left:-10000px" role="log" aria-live="assertive"></span></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;Leslie&quot;,&quot;itemId&quot;:52119092,&quot;title&quot;:&quot;NLP中的RNN、Seq2Seq与attention注意力机制&quot;,&quot;type&quot;:&quot;article&quot;}"><div class="ColumnPageHeader-Wrapper"><div><style data-emotion-css="1l12z7y">.css-1l12z7y{box-shadow:0px 16px 32px rgba(0,0,0,0.04);}</style><div class="Sticky ColumnPageHeader css-1l12z7y"><div class="ColumnPageHeader-content"><a href="//www.zhihu.com" aria-label="知乎"><style data-emotion-css="1hlrcxk">.css-1hlrcxk{-webkit-transition-property:fill;transition-property:fill;-webkit-transition-duration:0.25s;transition-duration:0.25s;-webkit-transition-timing-function:ease-in;transition-timing-function:ease-in;}</style><svg viewBox="0 0 64 30" fill="#0066FF" width="64" height="30" class="css-1hlrcxk"><path d="M29.05 4.582H16.733V25.94h3.018l.403 2.572 4.081-2.572h4.815V4.582zm-5.207 18.69l-2.396 1.509-.235-1.508h-1.724V7.233h6.78v16.04h-2.425zM14.46 14.191H9.982c0-.471.033-.954.039-1.458v-5.5h5.106V5.935a1.352 1.352 0 0 0-.404-.957 1.378 1.378 0 0 0-.968-.396H5.783c.028-.088.056-.177.084-.255.274-.82 1.153-3.326 1.153-3.326a4.262 4.262 0 0 0-2.413.698c-.57.4-.912.682-1.371 1.946-.532 1.453-.997 2.856-1.31 3.693C1.444 8.674.28 11.025.28 11.025a5.85 5.85 0 0 0 2.52-.61c1.119-.593 1.679-1.502 2.054-2.883l.09-.3h2.334v5.5c0 .5-.045.982-.073 1.46h-4.12c-.71 0-1.39.278-1.893.775a2.638 2.638 0 0 0-.783 1.874h6.527a17.717 17.717 0 0 1-.778 3.649 16.796 16.796 0 0 1-3.012 5.273A33.104 33.104 0 0 1 0 28.74s3.13 1.175 5.425-.954c1.388-1.292 2.631-3.814 3.23-5.727a28.09 28.09 0 0 0 1.12-5.229h5.967v-1.37a1.254 1.254 0 0 0-.373-.899 1.279 1.279 0 0 0-.909-.37z"></path><path d="M11.27 19.675l-2.312 1.491 5.038 7.458a6.905 6.905 0 0 0 .672-2.218 3.15 3.15 0 0 0-.28-2.168l-3.118-4.563zM51.449 15.195V5.842c4.181-.205 7.988-.405 9.438-.483l.851-.05c.387-.399.885-2.395.689-3.021-.073-.25-.213-.666-.638-.555a33.279 33.279 0 0 1-4.277.727c-2.766.321-3.97.404-7.804.682-6.718.487-12.709.72-12.709.72a2.518 2.518 0 0 0 .788 1.834 2.567 2.567 0 0 0 1.883.706c2.278-.095 5.598-.25 8.996-.41v9.203h-12.78c0 .703.281 1.377.783 1.874a2.69 2.69 0 0 0 1.892.777h10.105v7.075c0 .887-.464 1.192-1.231 1.214h-3.92a4.15 4.15 0 0 0 .837 1.544 4.2 4.2 0 0 0 1.403 1.067 6.215 6.215 0 0 0 2.71.277c1.36-.066 2.967-.826 2.967-3.57v-7.607h11.28c.342 0 .67-.135.91-.374.242-.239.378-.563.378-.902v-1.375H51.449z"></path><path d="M42.614 8.873a2.304 2.304 0 0 0-1.508-.926 2.334 2.334 0 0 0-1.727.405l-.376.272 4.255 5.85 2.24-1.62-2.884-3.98zM57.35 8.68l-3.125 4.097 2.24 1.663 4.517-5.927-.375-.277a2.32 2.32 0 0 0-1.722-.452 2.327 2.327 0 0 0-1.536.896z"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="//www.zhihu.com/column/sampleNLP">简单NLP</a></div></div><div class="ColumnPageHeader-Button"><style data-emotion-css="1emujq8">.css-1emujq8{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}.css-1emujq8:hover{color:#0066FF;}</style><style data-emotion-css="1ct7cfw">.css-1ct7cfw{box-sizing:border-box;margin:0;min-width:0;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-right:20px;color:#8590A6;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}.css-1ct7cfw:hover{color:#0066FF;}</style><button href="" class="css-1ct7cfw"><style data-emotion-css="1v994a0">.css-1v994a0{margin-right:6px;}</style><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="HeartFill24" data-old-api="Heart" class="Zi Zi--Heart css-1v994a0" fill="currentColor"><path d="M12.004 4.934c1.015-.944 2.484-1.618 3.98-1.618 3.48 0 6.53 3.265 6.15 7.614-.11 1.254-.686 2.55-1.458 3.753-.778 1.215-1.79 2.392-2.845 3.419-1.054 1.028-2.168 1.923-3.161 2.566a9.96 9.96 0 01-1.41.777c-.418.182-.862.32-1.268.32s-.848-.137-1.267-.317a9.918 9.918 0 01-1.407-.771c-.992-.64-2.103-1.53-3.156-2.555-1.052-1.024-2.062-2.2-2.84-3.417-.77-1.208-1.346-2.51-1.456-3.775-.38-4.349 2.67-7.614 6.15-7.614 1.484 0 2.983.673 3.988 1.618z" fill-rule="evenodd" clip-rule="evenodd"></path></svg>无障碍</button><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg width="24" height="24" viewBox="0 0 24 24" data-new-api="PencilPaper24" data-old-api="EditSurround" class="Zi Zi--EditSurround" fill="currentColor"><path d="M3.55 5.97a2.415 2.415 0 012.415-2.416h7.56a.75.75 0 010 1.5h-7.56a.915.915 0 00-.915.915v12.072c0 .505.41.915.915.915h12.074c.506 0 .915-.41.915-.915v-7.557a.75.75 0 011.5 0v7.557a2.415 2.415 0 01-2.415 2.415H5.965A2.415 2.415 0 013.55 18.04V5.969z" fill-rule="evenodd" clip-rule="evenodd"></path><path d="M20.239 3.77a.75.75 0 010 1.06l-8.206 8.206a.75.75 0 01-1.06-1.06l8.205-8.206a.75.75 0 011.06 0z" fill-rule="evenodd" clip-rule="evenodd"></path></svg>写文章</button></div></div><div class="ColumnPageHeader-profile"><div><style data-emotion-css="1ay9vb9">.css-1ay9vb9{margin-right:16px;}</style><style data-emotion-css="1aand3b">.css-1aand3b{display:inline-block;padding:0 16px;font-size:14px;line-height:32px;color:#FFFFFF;text-align:center;cursor:pointer;background:none;border:1px solid;border-radius:3px;background-color:#0066FF;border-color:#0066FF;margin-right:16px;}.css-1aand3b::mozFocusInner{padding:0;border:0;}.css-1aand3b:focus{outline:none;-webkit-transition:box-shadow 0.3s;transition:box-shadow 0.3s;}.css-1aand3b:focus-visible{box-shadow:0 0 0 2px #FFFFFF,0 0 0 4px rgba(0,102,255,0.3);}.css-1aand3b:disabled{cursor:default;opacity:0.5;}.css-1aand3b:hover{border-color:#0061f2;background-color:#0061f2;}</style><button type="button" class="Button css-1aand3b">登录/注册</button><style data-emotion-css="1fv1gmw">.css-1fv1gmw{position:fixed;bottom:50px;right:64px;width:336px;z-index:2;}</style></div></div></div></div></div><img class="TitleImage" src="https://pic2.zhimg.com/v2-4f760232b1cd7ab29749948a3656b027_1440w.jpg?source=172ae18b" alt="NLP中的RNN、Seq2Seq与attention注意力机制"/><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">NLP中的RNN、Seq2Seq与attention注意力机制</h1><div class="Post-Author"><div class="AuthorInfo" itemProp="author" itemscope="" itemType="http://schema.org/Person"><div class="AuthorInfo"><meta itemProp="name" content="Leslie"/><meta itemProp="image" content="https://pica.zhimg.com/v2-2b66bc8b3dab8cac5bb1d5a714bb1f32_l.jpg?source=172ae18b"/><meta itemProp="url" content="https://www.zhihu.com/people/robin-feng-41"/><meta itemProp="zhihu:followerCount"/><span class="UserLink AuthorInfo-avatarWrapper"><a href="//www.zhihu.com/people/robin-feng-41" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="https://pica.zhimg.com/v2-2b66bc8b3dab8cac5bb1d5a714bb1f32_xs.jpg?source=172ae18b" srcSet="https://pica.zhimg.com/v2-2b66bc8b3dab8cac5bb1d5a714bb1f32_l.jpg?source=172ae18b 2x" alt="Leslie"/></a></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><a href="//www.zhihu.com/people/robin-feng-41" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User">Leslie</a><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="ztext AuthorInfo-badgeText">研究NLP方向。</div></div></div></div></div></div></div><div role="button" tabindex="0"><span class="Voters"><button type="button" class="Button Button--plain">148 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><style data-emotion-css="1yuhvjn">.css-1yuhvjn{margin-top:16px;}</style><div class="css-1yuhvjn"><style data-emotion-css="3jt6os">.css-3jt6os .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-3jt6os .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-3jt6os .FileLinkCard-info{margin-left:12px;}.css-3jt6os .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-3jt6os .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-3jt6os .FileLinkCard-source{white-space:pre;}</style><style data-emotion-css="1wr1m8">.css-1wr1m8 .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-1wr1m8 .LinkCard.new,.css-1wr1m8 .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1wr1m8 .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1wr1m8 .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-1wr1m8 .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1wr1m8 .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1wr1m8 .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1wr1m8 .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1wr1m8 .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1wr1m8 .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1wr1m8 .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1wr1m8 .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-1wr1m8 .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1wr1m8 .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1wr1m8 .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-1wr1m8 .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1wr1m8 .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1wr1m8 .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1wr1m8 .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-1wr1m8 .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-1wr1m8 .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1wr1m8 .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1wr1m8 .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-1wr1m8 .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-1wr1m8 .LinkCard.new .LinkCard-richText .bold{font-weight:600;}.css-1wr1m8 .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1wr1m8 .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1wr1m8 .LinkCard.old,.css-1wr1m8 .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1wr1m8 .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}</style><style data-emotion-css="hypxot">.css-hypxot .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-hypxot .LinkCard.old,.css-hypxot .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-hypxot .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-hypxot .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-hypxot .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-hypxot .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-hypxot .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-hypxot .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-hypxot .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-hypxot .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-hypxot .LinkCard.new,.css-hypxot .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-hypxot .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-hypxot .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-hypxot .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-hypxot .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-hypxot .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-hypxot .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-hypxot .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-hypxot .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-hypxot .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-hypxot .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-hypxot .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-hypxot .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-hypxot .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-hypxot .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-hypxot .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-hypxot .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-hypxot .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-hypxot .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-hypxot .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-hypxot .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-hypxot .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-hypxot .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-hypxot .LinkCard.new .LinkCard-richText .bold{font-weight:600;}.css-hypxot .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-hypxot .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-hypxot .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-hypxot .FileLinkCard-info{margin-left:12px;}.css-hypxot .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-hypxot .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-hypxot .FileLinkCard-source{white-space:pre;}</style><style data-emotion-css="9scqi7 animation-1sh55c5">.css-9scqi7{word-break:break-word;line-height:1.6;}.css-9scqi7 a.UserLink-link{color:#175199;}.css-9scqi7 a.UserLink-link:hover{border-bottom:1px solid #175199;}.css-9scqi7 lazy[data-lazy-status]{background-color:#F6F6F6;}.css-9scqi7 lazy[data-lazy-status="ok"]{background-color:transparent;-webkit-animation:animation-1sh55c5 0.5s ease-in;animation:animation-1sh55c5 0.5s ease-in;}.css-9scqi7 > [data-first-child]{margin-top:0;}.css-9scqi7 > :last-child{margin-bottom:0;}.css-9scqi7 h1,.css-9scqi7 h2{clear:left;margin-top:calc((1.4em * 2) / 1.2);margin-bottom:calc(1.4em / 1.2);font-size:1.2em;line-height:1.5;font-weight:600;}.css-9scqi7 h3,.css-9scqi7 h4,.css-9scqi7 h5,.css-9scqi7 h6{clear:left;margin-top:calc((1.4em * 1.5) / 1.1);margin-bottom:calc(1.4em / 1.1);font-size:1.1em;line-height:1.5;font-weight:600;}.css-9scqi7 u{-webkit-text-decoration:none;text-decoration:none;border-bottom:1px solid #444444;}.css-9scqi7 b{font-weight:600;}.css-9scqi7 sup{font-size:0.8em;}.css-9scqi7 sup[data-draft-type='reference']{color:#175199;}.css-9scqi7 a:focus{outline:none;-webkit-transition:box-shadow 0.3s;transition:box-shadow 0.3s;}html[data-focus-visible] .css-9scqi7 a:focus{box-shadow:0 0 0 2px #FFFFFF,0 0 0 4px rgba(0,102,255,0.3);}.css-9scqi7 a.ztext-link,.css-9scqi7 a.internal,.css-9scqi7 a.external{-webkit-text-decoration:none;text-decoration:none;cursor:pointer;border-bottom:1px solid #808080;}.css-9scqi7 a.ztext-link:hover,.css-9scqi7 a.internal:hover,.css-9scqi7 a.external:hover{color:#175199;border-bottom:1px solid #175199;}.css-9scqi7 a.ztext-link > .ellipsis::after,.css-9scqi7 a.internal > .ellipsis::after,.css-9scqi7 a.external > .ellipsis::after{content:'...';}.css-9scqi7 a.ztext-link > .invisible,.css-9scqi7 a.internal > .invisible,.css-9scqi7 a.external > .invisible{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;}.css-9scqi7 a.ztext-link u,.css-9scqi7 a.internal u,.css-9scqi7 a.external u{border:none;}.css-9scqi7 a.member_mention{color:#175199;}.css-9scqi7 a.member_mention:hover{border-bottom:1px solid #175199;}.css-9scqi7 p{margin:1.4em 0;}.css-9scqi7 p.ztext-empty-paragraph{margin:calc((2.8em- (1.4em * 2 + 1.6em)) / 2) 0;}.css-9scqi7 p.ztext-empty-paragraph + .ztext-empty-paragraph{margin:1.4em 0;}.css-9scqi7 hr{margin:4em auto;width:240px;max-width:100%;border:none;border-top:1px solid #D3D3D3;}.css-9scqi7 img[eeimg]{max-width:100%;vertical-align:middle;}.css-9scqi7 img[eeimg="1"]{margin:0 3px;max-width:calc(100% - 6px);display:inline-block;}.css-9scqi7 img[eeimg="2"]{margin:1.4em auto;display:block;}.css-9scqi7 blockquote{margin:1.4em 0;padding-left:1em;color:#646464;border-left:3px solid #D3D3D3;}.css-9scqi7 ol,.css-9scqi7 ul{margin:1.4em 0;padding:0;}.css-9scqi7 ol ol,.css-9scqi7 ul ol,.css-9scqi7 ol ul,.css-9scqi7 ul ul{margin:0;}.css-9scqi7 ol > ol,.css-9scqi7 ul > ol,.css-9scqi7 ol > ul,.css-9scqi7 ul > ul{display:table-row;}.css-9scqi7 ol > ol::before,.css-9scqi7 ul > ol::before,.css-9scqi7 ol > ul::before,.css-9scqi7 ul > ul::before{display:table-cell;content:'';}.css-9scqi7 ul{display:table;}.css-9scqi7 ul>li{display:table-row;list-style:none;}.css-9scqi7 ul>li::before{display:table-cell;content:'•  ';white-space:pre;}.css-9scqi7 ol{display:table;counter-reset:ol;}.css-9scqi7 ol > li{display:table-row;list-style:none;}.css-9scqi7 ol > li::before{display:table-cell;text-align:right;counter-increment:ol;content:counter(ol) '. ';white-space:pre;}.css-9scqi7 ol ol{counter-reset:ol2;}.css-9scqi7 ol ol li::before{counter-increment:ol2;content:counter(ol2) '. ';}.css-9scqi7 ol ol ol{counter-reset:ol3;}.css-9scqi7 ol ol ol li::before{counter-increment:ol3;content:counter(ol3) '. ';}.css-9scqi7 ol ol ol ol{counter-reset:ol4;}.css-9scqi7 ol ol ol ol li::before{counter-increment:ol4;content:counter(ol4) '. ';}.css-9scqi7 figure{margin:1.4em 0;}.css-9scqi7 figure .content_image,.css-9scqi7 figure .origin_image{margin:0 auto;}.css-9scqi7 figure figcaption{margin-top:calc(0.6em / 0.9);padding:0 1em;font-size:0.9em;line-height:1.5;text-align:center;color:#999999;}.css-9scqi7 figure + figure{margin-top:calc(1.4em * 1.6);}.css-9scqi7 figure[data-size='small'],.css-9scqi7 figure:not([data-size]) > [data-size='small']{clear:both;}.css-9scqi7 figure[data-size='left'],.css-9scqi7 figure:not([data-size]) > [data-size='left']{float:left;margin:0 20px 20px 0;max-width:33%;}.css-9scqi7 figure[data-size='right'],.css-9scqi7 figure:not([data-size]) > [data-size='right']{float:right;margin:0 0 20px 20px;max-width:33%;}.css-9scqi7 figure[data-size='collapse']{margin-bottom:0;}.css-9scqi7 figure[data-size='collapse'] + figure{margin-top:0;}.css-9scqi7 .content_image,.css-9scqi7 .origin_image{display:block;max-width:100%;margin:1.4em auto;}.css-9scqi7 .content_image[data-size='small'],.css-9scqi7 .origin_image[data-size='small']{max-width:40%;}.css-9scqi7 .content_image.zh-lightbox-thumb,.css-9scqi7 .origin_image.zh-lightbox-thumb{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;}.css-9scqi7 code{margin:0 2px;padding:3px 4px;border-radius:3px;font-size:0.9em;background-color:#F6F6F6;}.css-9scqi7 pre{margin:1.4em 0;padding:calc(0.8em / 0.9);font-size:0.9em;word-break:initial;word-wrap:initial;white-space:pre;overflow:auto;-webkit-overflow-scrolling:touch;background:#F6F6F6;border-radius:4px;}.css-9scqi7 pre code{margin:0;padding:0;font-size:inherit;border-radius:0;background-color:inherit;}.css-9scqi7 li pre{white-space:pre-wrap;}.css-9scqi7 table[data-draft-type='table']{border-collapse:collapse;font-size:15px;margin:1.4em auto;max-width:100%;table-layout:fixed;text-align:left;width:100%;}.css-9scqi7 table[data-draft-type='table'][data-size='small']{min-width:260px;width:40%;}.css-9scqi7 table[data-draft-type='table'][data-row-style='striped'] tr:nth-of-type(2n + 1){background:#F6F6F6;}.css-9scqi7 table[data-draft-type='table'] td,.css-9scqi7 table[data-draft-type='table'] th{border:1px solid #D3D3D3;line-height:24px;height:24px;padding:3px 12px;}.css-9scqi7 table[data-draft-type='table'] th{background:#EBEBEB;color:#121212;font-weight:500;}.css-9scqi7 .video-box,.css-9scqi7 .link-box{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;margin:1.4em 0;overflow:auto;white-space:normal;cursor:pointer;border:solid 1px #EBEBEB;border-radius:4px;}.css-9scqi7 .highlight{margin:1em 0;}.css-9scqi7 .highlight pre{margin:0;}.css-9scqi7 .highlight .hll{background-color:#FDFDFD;}.css-9scqi7 .highlight .c{font-style:italic;color:#999999;}.css-9scqi7 .highlight .err{color:#F1403C;}.css-9scqi7 .highlight .k{font-weight:600;}.css-9scqi7 .highlight .o{font-weight:600;}.css-9scqi7 .highlight .cm{font-style:italic;color:#999999;}.css-9scqi7 .highlight .cp{font-weight:600;color:#999999;}.css-9scqi7 .highlight .c1{font-style:italic;color:#999999;}.css-9scqi7 .highlight .cs{font-style:italic;font-weight:600;color:#999999;}.css-9scqi7 .highlight .gd{color:#FF3366;}.css-9scqi7 .highlight .ge{font-style:italic;}.css-9scqi7 .highlight .gr{color:#F1403C;}.css-9scqi7 .highlight .gh{color:#999999;}.css-9scqi7 .highlight .gi{color:#12b370;}.css-9scqi7 .highlight .go{color:#808080;}.css-9scqi7 .highlight .gp{color:#646464;}.css-9scqi7 .highlight .gs{font-weight:600;}.css-9scqi7 .highlight .gu{color:#999999;}.css-9scqi7 .highlight .gt{color:#F1403C;}.css-9scqi7 .highlight .kc{font-weight:600;}.css-9scqi7 .highlight .kd{font-weight:600;}.css-9scqi7 .highlight .kn{font-weight:600;}.css-9scqi7 .highlight .kp{font-weight:600;}.css-9scqi7 .highlight .kr{font-weight:600;}.css-9scqi7 .highlight .kt{font-weight:600;color:#175199;}.css-9scqi7 .highlight .m{color:#0066FF;}.css-9scqi7 .highlight .s{color:#F1403C;}.css-9scqi7 .highlight .na{color:#0066FF;}.css-9scqi7 .highlight .nb{color:#0066FF;}.css-9scqi7 .highlight .nc{font-weight:600;color:#175199;}.css-9scqi7 .highlight .no{color:#0066FF;}.css-9scqi7 .highlight .ni{color:#5555DD;}.css-9scqi7 .highlight .ne{font-weight:600;color:#F1403C;}.css-9scqi7 .highlight .nf{font-weight:600;color:#F1403C;}.css-9scqi7 .highlight .nn{color:#646464;}.css-9scqi7 .highlight .nt{color:#175199;}.css-9scqi7 .highlight .nv{color:#0066FF;}.css-9scqi7 .highlight .ow{font-weight:600;}.css-9scqi7 .highlight .w{color:#BFBFBF;}.css-9scqi7 .highlight .mf{color:#0066FF;}.css-9scqi7 .highlight .mh{color:#0066FF;}.css-9scqi7 .highlight .mi{color:#0066FF;}.css-9scqi7 .highlight .mo{color:#0066FF;}.css-9scqi7 .highlight .sb{color:#F1403C;}.css-9scqi7 .highlight .sc{color:#F1403C;}.css-9scqi7 .highlight .sd{color:#F1403C;}.css-9scqi7 .highlight .s2{color:#F1403C;}.css-9scqi7 .highlight .se{color:#F1403C;}.css-9scqi7 .highlight .sh{color:#F1403C;}.css-9scqi7 .highlight .si{color:#F1403C;}.css-9scqi7 .highlight .sx{color:#F1403C;}.css-9scqi7 .highlight .sr{color:#A5542F;}.css-9scqi7 .highlight .s1{color:#F1403C;}.css-9scqi7 .highlight .ss{color:#F1403C;}.css-9scqi7 .highlight .bp{color:#999999;}.css-9scqi7 .highlight .vc{color:#0066FF;}.css-9scqi7 .highlight .vg{color:#0066FF;}.css-9scqi7 .highlight .vi{color:#0066FF;}.css-9scqi7 .highlight .il{color:#0066FF;}.css-9scqi7 .highlight::-webkit-scrollbar{width:6px;height:6px;}.css-9scqi7 .highlight::-webkit-scrollbar-thumb:horizontal{background-color:rgba(18,18,18,0.5);border-radius:6px;}.css-9scqi7 .highlight::-webkit-scrollbar-thumb:horizontal:hover{background-color:rgba(18,18,18,0.6);}.css-9scqi7 .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-9scqi7 .LinkCard.old,.css-9scqi7 .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-9scqi7 .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-9scqi7 .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-9scqi7 .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-9scqi7 .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-9scqi7 .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-9scqi7 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-9scqi7 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-9scqi7 .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-9scqi7 .LinkCard.new,.css-9scqi7 .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-9scqi7 .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-9scqi7 .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-9scqi7 .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-9scqi7 .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-9scqi7 .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-9scqi7 .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-9scqi7 .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-9scqi7 .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-9scqi7 .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-9scqi7 .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-9scqi7 .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-9scqi7 .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-9scqi7 .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-9scqi7 .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-9scqi7 .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-9scqi7 .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-9scqi7 .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-9scqi7 .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-9scqi7 .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-9scqi7 .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-9scqi7 .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-9scqi7 .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-9scqi7 .LinkCard.new .LinkCard-richText .bold{font-weight:600;}.css-9scqi7 .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-9scqi7 .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-9scqi7 .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-9scqi7 .FileLinkCard-info{margin-left:12px;}.css-9scqi7 .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-9scqi7 .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-9scqi7 .FileLinkCard-source{white-space:pre;}@-webkit-keyframes animation-1sh55c5{from{opacity:0;}to{opacity:1;}}@keyframes animation-1sh55c5{from{opacity:0;}to{opacity:1;}}</style><div class="RichText ztext Post-RichText css-9scqi7" options="[object Object]"><h2 data-first-child><b>RNN循环神经网络</b></h2><p data-pid="VGw3beqC">RNN循环神经网络被广泛应用于自然语言处理中，对于处理序列数据有很好的效果，常见的序列数据有文本、语音等，至于为什么要用到循环神经网络而不是传统的神经网络，我们在这里举一个例子。</p><p data-pid="cY91hFhC">假如有一个智能订票系统，我只需要输入一句话，该系统能识别出我将在什么时间订购去哪里的车票。那么程序需要根据我们输入的文本识别出我们出发的时间，目的地以及始发地。</p><p data-pid="9ehhIXRk">如:我一月一号去郑州。</p><p data-pid="rZaFDwvZ">那么“一月一号”是时间，“郑州”是目的地，“我”和“去”都是其他不需要提取的信息，我们统一归为其他类。</p><p data-pid="rWmBLFo4">那么假如我输入另外一个句子:</p><p data-pid="VYYyzYZ2">我一月一号离开郑州</p><p data-pid="tEmkERym">此时“一月一号”是时间，“郑州”就变成了始发地，“我”和“离开”都是其他。</p><p data-pid="iOkImX4C">针对这个例子，我输入不同的文本，郑州表示为不同的label,用前馈神经网络去做的话，就不能将两个不同语境下的“郑州”区分开，所以这时我们需要我们的神经网络具有记忆功能，即，当在看到第一个文本中的“郑州”的时候，神经网络已经存储了“去”这个词的信息。当在看到第二个文本中的“郑州”的时候就已经存储了“离开”这个词的信息，因为“去”和“离开”两个词的信息不同，故就可以将两个文本中的“郑州”区分开。</p><p data-pid="fLr5ABzJ">下面我们根据这个例子去了解循环神经网络的结构</p><p data-pid="e7TxQHi2">对于一个文本的每一个词可以看做是一个时序。RNN的每一个时序是一个前馈神经网络，但是为了在每一个时刻都包含前边时序的信息，所以RNN的每个时序共享了隐藏层，即当前时刻的输入不仅包含了当前时刻的词，还包含了前一时刻的隐藏层的输出。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-aa1137939edb1de9a6230f7b910f0209_b.jpg" data-size="normal" data-rawwidth="1920" data-rawheight="776" class="origin_image zh-lightbox-thumb" width="1920" data-original="https://pic2.zhimg.com/v2-aa1137939edb1de9a6230f7b910f0209_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1920&#39; height=&#39;776&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="1920" data-rawheight="776" class="origin_image zh-lightbox-thumb lazy" width="1920" data-original="https://pic2.zhimg.com/v2-aa1137939edb1de9a6230f7b910f0209_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-aa1137939edb1de9a6230f7b910f0209_b.jpg"/><figcaption>RNN结构图</figcaption></figure><p class="ztext-empty-paragraph"><br/></p><p data-pid="8-95VvaH">因为计算机并不能读懂汉字，所以我们一般会用向量的方式去表示一个词。</p><p data-pid="3a3I-je9">向量表示词的方法有很多，常用的比如one-hot、词袋模型、词嵌入等。</p><p data-pid="Uo2FIDEC">在本例中为了方便计算在这里我们使用：</p><p data-pid="ChK9aTxq">[1,1]表示我</p><p data-pid="1ro3z3qR">[2,2]表示去</p><p data-pid="uIbcMoO4">[3,3]表示离开</p><p data-pid="UwjZ-bsk">[4,4]表示郑州</p><p data-pid="QB5AnuDF">并且假设所有的权重都是1，所有的偏置都是0。</p><p data-pid="kGLecYsV">下图为“我去郑州”的循环神经网络结构图。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-73730b3454aee066f0d0355ff2051f6c_b.jpg" data-size="normal" data-rawwidth="744" data-rawheight="435" class="origin_image zh-lightbox-thumb" width="744" data-original="https://pic1.zhimg.com/v2-73730b3454aee066f0d0355ff2051f6c_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;744&#39; height=&#39;435&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="744" data-rawheight="435" class="origin_image zh-lightbox-thumb lazy" width="744" data-original="https://pic1.zhimg.com/v2-73730b3454aee066f0d0355ff2051f6c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-73730b3454aee066f0d0355ff2051f6c_b.jpg"/><figcaption>我去郑州</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-610a0575cb798e88c4fe471c9eafb19a_b.jpg" data-size="normal" data-rawwidth="748" data-rawheight="430" class="origin_image zh-lightbox-thumb" width="748" data-original="https://pic3.zhimg.com/v2-610a0575cb798e88c4fe471c9eafb19a_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;748&#39; height=&#39;430&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="748" data-rawheight="430" class="origin_image zh-lightbox-thumb lazy" width="748" data-original="https://pic3.zhimg.com/v2-610a0575cb798e88c4fe471c9eafb19a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-610a0575cb798e88c4fe471c9eafb19a_b.jpg"/><figcaption>我离开郑州</figcaption></figure><p data-pid="8iETW872">下图为“我离开郑州”的循环神经网络结构图。</p><p data-pid="dUlbrCg1">我们看到，因为“去”和“离开”的词向量不同，所以在循环神经网络中最后的“郑州”的输出也不相同，这样就能把两个“郑州”给区分开来了。</p><p data-pid="0-ptZDQT">根据上边的例子可以看出来，循环神经网络中每一个时序的隐藏层不仅包含了前边时序的输入信息，也包含了前边时序的顺序信息。可以理解为包含了前边时序的语义信息。</p><p data-pid="4Turc4Np">循环神经网络展开图:</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-8bb4944dbeb62636ce52b299dc72af47_b.jpg" data-size="normal" data-rawwidth="484" data-rawheight="229" class="origin_image zh-lightbox-thumb" width="484" data-original="https://pic4.zhimg.com/v2-8bb4944dbeb62636ce52b299dc72af47_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;484&#39; height=&#39;229&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="484" data-rawheight="229" class="origin_image zh-lightbox-thumb lazy" width="484" data-original="https://pic4.zhimg.com/v2-8bb4944dbeb62636ce52b299dc72af47_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-8bb4944dbeb62636ce52b299dc72af47_b.jpg"/><figcaption>RNN展开图</figcaption></figure><p data-pid="ruRCJGD7">可以看出，每一个时刻的输出不仅包含了该时刻的输入向量，也包含了前一时刻的隐藏层的输出。具体的计算公式如下:</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-5616fcfed2821b4667430325048b572f_b.jpg" data-caption="" data-size="normal" data-rawwidth="225" data-rawheight="59" class="content_image" width="225"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;225&#39; height=&#39;59&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="225" data-rawheight="59" class="content_image lazy" width="225" data-actualsrc="https://pic4.zhimg.com/v2-5616fcfed2821b4667430325048b572f_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-fccd1aa7bb7e1d12a398146ff449d9c1_b.jpg" data-caption="" data-size="normal" data-rawwidth="421" data-rawheight="63" class="origin_image zh-lightbox-thumb" width="421" data-original="https://pic2.zhimg.com/v2-fccd1aa7bb7e1d12a398146ff449d9c1_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;421&#39; height=&#39;63&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="421" data-rawheight="63" class="origin_image zh-lightbox-thumb lazy" width="421" data-original="https://pic2.zhimg.com/v2-fccd1aa7bb7e1d12a398146ff449d9c1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-fccd1aa7bb7e1d12a398146ff449d9c1_b.jpg"/></figure><h2><b>seq2seq模型</b></h2><p data-pid="7JTRY3im">刚才的例子其实是N对N的循环神经网络，即我的输入序列长度是N,输出也是对应的N长度的序列。其实循环神经网络还有其他的比如:1对N、N对1。</p><p data-pid="sRhisK1s">但很多时候我们会遇到输入序列和输出序列不等长的例子但又不是1对N和N对1，如机器翻译，智能问答，源语言和目标语言的句子往往并没有相同的长度。为此我们引出RNN最重要的一个变种：N vs M。这种结构又叫Encoder-Decoder模型，也可以称之为Seq2Seq模型。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-5c62edab9ef404f1802c9637fcafbfaf_b.jpg" data-size="normal" data-rawwidth="720" data-rawheight="289" class="origin_image zh-lightbox-thumb" width="720" data-original="https://pic4.zhimg.com/v2-5c62edab9ef404f1802c9637fcafbfaf_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;720&#39; height=&#39;289&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="720" data-rawheight="289" class="origin_image zh-lightbox-thumb lazy" width="720" data-original="https://pic4.zhimg.com/v2-5c62edab9ef404f1802c9637fcafbfaf_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-5c62edab9ef404f1802c9637fcafbfaf_b.jpg"/><figcaption>seq2seq模型</figcaption></figure><p data-pid="pPSzza8C">还有一种做法是将c当做每一步的输入：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-6d615b290998f8c44bc46782b244bf2f_b.jpg" data-size="normal" data-rawwidth="720" data-rawheight="398" class="origin_image zh-lightbox-thumb" width="720" data-original="https://pic4.zhimg.com/v2-6d615b290998f8c44bc46782b244bf2f_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;720&#39; height=&#39;398&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="720" data-rawheight="398" class="origin_image zh-lightbox-thumb lazy" width="720" data-original="https://pic4.zhimg.com/v2-6d615b290998f8c44bc46782b244bf2f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-6d615b290998f8c44bc46782b244bf2f_b.jpg"/><figcaption>seq2seq模型</figcaption></figure><p data-pid="XMoAja5_">对于序列到序列的数据来说，可以把Encoder和Decoder分别看成是RNN，在Encoder中根据输入数据生成一个语义编码C，C的获取方式有很多种，最简单的就是把Encoder中最后一个隐藏层赋值给C，也可以对最后一个隐藏状态做一个变换得到C，还可以对所有的隐藏状态做变换得到C。</p><p data-pid="wxpwyk55">拿到C之后，就可以用另一个RNN进行解码，这部分RNN被称为Decoder，具体做法就是将C当做之前的初始状态h0输入到Decoder中，C还有一种做法是将C当做每一步的输入。</p><p data-pid="_7utBpjN">这里我们用一个机器翻译的例子解释seq2seq模型。</p><p data-pid="jTvYOke9">例:机器学习翻译 成 machine learning</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-ed423dc7c4354adce7612d8db77f19ca_b.jpg" data-caption="" data-size="normal" data-rawwidth="694" data-rawheight="338" class="origin_image zh-lightbox-thumb" width="694" data-original="https://pic3.zhimg.com/v2-ed423dc7c4354adce7612d8db77f19ca_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;694&#39; height=&#39;338&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="694" data-rawheight="338" class="origin_image zh-lightbox-thumb lazy" width="694" data-original="https://pic3.zhimg.com/v2-ed423dc7c4354adce7612d8db77f19ca_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-ed423dc7c4354adce7612d8db77f19ca_b.jpg"/></figure><h2><b>Attention（注意力机制）</b></h2><p data-pid="TB0tZqS2">图片展示的Encoder-Decoder框架是没有体现“注意力模型”的，所以可以把它看做是注意力不集中分心模型。因为在生成目标句子的单词时，不论生成哪个单词，它们使用的输入句子的语义编码C都是一样的，没有任何区别。而语义编码C是由原句子中的每个单词经过Encoder编码产生的，这意味着原句子中任意单词对生成某个目标单词来说影响力都是相同的，这就是模型没有体现出注意力的缘由。</p><p data-pid="_TVfz-Xl">在上边那个例子中在生成“machine”时，&#34;机&#34;,&#34;器&#34;,&#34;学&#34;,&#34;&#34;习&#34;的贡献是相同的，很明显，这是不太合理，显然，&#34;机&#34;,&#34;器&#34;，对于翻译成&#34;machine&#34;更为重要。所以我们希望在模型翻译&#34;machine&#34;的时候，&#34;机&#34;，&#34;器&#34;两个字的贡献(权重)更大，当在翻译成&#34;learning&#34;时，&#34;学&#34;，&#34;习&#34;两个字贡献(权重)更大。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-9407244671e4bc4fa32da7e66fba25bf_b.jpg" data-caption="" data-size="normal" data-rawwidth="747" data-rawheight="189" class="origin_image zh-lightbox-thumb" width="747" data-original="https://pic4.zhimg.com/v2-9407244671e4bc4fa32da7e66fba25bf_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;747&#39; height=&#39;189&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="747" data-rawheight="189" class="origin_image zh-lightbox-thumb lazy" width="747" data-original="https://pic4.zhimg.com/v2-9407244671e4bc4fa32da7e66fba25bf_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-9407244671e4bc4fa32da7e66fba25bf_b.jpg"/></figure><p data-pid="C0GIj2as">上图中，输入序列上是“机器学习”，因此Encoder中的h1、h2、h3、h4分别代表“机&#34;,&#34;器&#34;,&#34;学&#34;,&#34;习”的信息，在翻译&#34;macine&#34;时，第一个上下文向量C1应该和&#34;机&#34;,&#34;器&#34;两个字最相关，所以对应的权重a比较大，在翻译&#34;learning&#34;时，第二个上下文向量C2应该和&#34;学&#34;,&#34;习&#34;两个字最相关，所以&#34;学&#34;,&#34;习&#34;对应的权重a比较大。</p><p data-pid="blfAY9DT">a其实是一个0-1之间的值，a可以看成是e的softmax后的结果。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-78c7c4bcfeee2842321c93494f4d5fe3_b.jpg" data-size="normal" data-rawwidth="761" data-rawheight="434" class="origin_image zh-lightbox-thumb" width="761" data-original="https://pic4.zhimg.com/v2-78c7c4bcfeee2842321c93494f4d5fe3_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;761&#39; height=&#39;434&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="761" data-rawheight="434" class="origin_image zh-lightbox-thumb lazy" width="761" data-original="https://pic4.zhimg.com/v2-78c7c4bcfeee2842321c93494f4d5fe3_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-78c7c4bcfeee2842321c93494f4d5fe3_b.jpg"/><figcaption>翻译matchine</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-1439a5032b0997ef3e5861359026b2ea_b.jpg" data-size="normal" data-rawwidth="754" data-rawheight="423" class="origin_image zh-lightbox-thumb" width="754" data-original="https://pic3.zhimg.com/v2-1439a5032b0997ef3e5861359026b2ea_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;754&#39; height=&#39;423&#39;&gt;&lt;/svg&gt;" data-size="normal" data-rawwidth="754" data-rawheight="423" class="origin_image zh-lightbox-thumb lazy" width="754" data-original="https://pic3.zhimg.com/v2-1439a5032b0997ef3e5861359026b2ea_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-1439a5032b0997ef3e5861359026b2ea_b.jpg"/><figcaption>翻译learning</figcaption></figure><p data-pid="08RRJj55">那现在关于<b>attention</b>来说就只剩下一个问题了，就是e是怎么来的。关于e的计算，业界有很多种方法，常用的有以下三种方式:</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-2dabbf1328362b4e2354f29b2dd210bf_b.jpg" data-caption="" data-size="normal" data-rawwidth="377" data-rawheight="148" class="content_image" width="377"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;377&#39; height=&#39;148&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="377" data-rawheight="148" class="content_image lazy" width="377" data-actualsrc="https://pic4.zhimg.com/v2-2dabbf1328362b4e2354f29b2dd210bf_b.jpg"/></figure><ol><li data-pid="qX1nvcaI">计算Encoder的序列h与Decoder的序列h的余弦相似度.</li><li data-pid="BbgwB1xN">在1的基础上，乘上一个Wa，Wa是需要学习的参数，从学习到Encoder和Decoder的隐藏的打分e。</li><li data-pid="yKxQ2fRC">设计一个前馈神经网络，前馈神经网络的输入是Encoder和Decoder的两个隐藏状态，Va、Wa都是需要学习的参数。</li></ol><h2>总结</h2><p data-pid="3oqt3NNF">     到这里，本文已经介绍了RNN循环神经网络的基本概念，seq2seq模型的基本概念及seq2seq中的注意力机制，希望能帮到大家。</p><h2><b>引用</b></h2><p data-pid="AJt4XDJA">本文关于<b>seq2seq</b>模型中的三张图引用了<b><a href="https://zhuanlan.zhihu.com/p/28054589" class="internal">完全图解RNN、RNN变体、Seq2Seq、Attention机制</a>，</b>在此表示感谢<b>。</b></p></div></div></div><div role="button" tabindex="0" class="ContentItem-time">编辑于 2019-08-12 22:55</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20086967" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">RNN</div></div></a></span></div><div class="Tag Topic"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20682987" target="_blank"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">注意力机制</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-bottom"><div class="ContentItem-actions"><span><button aria-label="赞同 148 " aria-live="polite" type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" data-new-api="AgreeFill24" data-old-api="TriangleUp" class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor"><path d="M13.792 3.681c-.781-1.406-2.803-1.406-3.584 0l-7.79 14.023c-.76 1.367.228 3.046 1.791 3.046h15.582c1.563 0 2.55-1.68 1.791-3.046l-7.79-14.023z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>赞同 148</button><button aria-label="反对" aria-live="polite" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" data-new-api="OpposeFill24" data-old-api="TriangleDown" class="Zi Zi--TriangleDown" fill="currentColor"><path d="M13.792 20.319c-.781 1.406-2.803 1.406-3.584 0L2.418 6.296c-.76-1.367.228-3.046 1.791-3.046h15.582c1.563 0 2.55 1.68 1.791 3.046l-7.79 14.023z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="Comment" class="Zi Zi--Comment Button-zi" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>9 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="PaperplaneFill24" data-old-api="Share" class="Zi Zi--Share Button-zi" fill="currentColor"><path d="M19.47 1.914a.8.8 0 011.204.778l-1.872 16.386a.9.9 0 01-1.204.743l-4.615-1.692a.7.7 0 00-.831.28l-1.927 3.02c-.43.674-1.474.369-1.474-.43v-3.865a.8.8 0 01.179-.504l5.808-7.148a.595.595 0 00-.897-.781l-5.93 6.354a1.1 1.1 0 01-1.258.252L2.57 13.46a.8.8 0 01-.08-1.415l16.98-10.13z"></path></svg></span>分享</button></div></div><button aria-live="polite" type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="HeartFill24" data-old-api="Heart" class="Zi Zi--Heart Button-zi" fill="currentColor"><path d="M12.004 4.934c1.015-.944 2.484-1.618 3.98-1.618 3.48 0 6.53 3.265 6.15 7.614-.11 1.254-.686 2.55-1.458 3.753-.778 1.215-1.79 2.392-2.845 3.419-1.054 1.028-2.168 1.923-3.161 2.566a9.96 9.96 0 01-1.41.777c-.418.182-.862.32-1.268.32s-.848-.137-1.267-.317a9.918 9.918 0 01-1.407-.771c-.992-.64-2.103-1.53-3.156-2.555-1.052-1.024-2.062-2.2-2.84-3.417-.77-1.208-1.346-2.51-1.456-3.775-.38-4.349 2.67-7.614 6.15-7.614 1.484 0 2.983.673 3.988 1.618z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="StarFill24" data-old-api="Star" class="Zi Zi--Star Button-zi" fill="currentColor"><path d="M10.484 3.307c.673-1.168 2.358-1.168 3.032 0l2.377 4.122a.25.25 0 00.165.12l4.655.987c1.319.28 1.84 1.882.937 2.884l-3.186 3.535a.25.25 0 00-.063.193l.5 4.733c.142 1.34-1.222 2.33-2.453 1.782l-4.346-1.938a.25.25 0 00-.204 0l-4.346 1.938c-1.231.549-2.595-.442-2.453-1.782l.5-4.733a.25.25 0 00-.064-.193L2.35 11.42c-.903-1.002-.382-2.604.937-2.884l4.655-.987a.25.25 0 00.164-.12l2.378-4.122z"></path></svg></span>收藏</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="TrayFullFill24" data-old-api="Deliver" class="Zi Zi--Deliver Button-zi" fill="currentColor"><g fill-rule="evenodd" clip-rule="evenodd"><path d="M7.821 12a.75.75 0 01.75-.75h6.857a.75.75 0 010 1.5H8.571a.75.75 0 01-.75-.75zm1.144-4a.75.75 0 01.75-.75h4.571a.75.75 0 010 1.5H9.715a.75.75 0 01-.75-.75z"></path><path d="M7.527 3.15a2.35 2.35 0 00-2.309 1.91L3.165 15.84a.85.85 0 00-.015.16v2.5a2.35 2.35 0 002.35 2.35h13a2.35 2.35 0 002.35-2.35V16a.848.848 0 00-.015-.16L18.78 5.06a2.35 2.35 0 00-2.308-1.91H7.527zm0 1.7a.65.65 0 00-.639.528l-1.88 9.872h13.984l-1.88-9.872a.65.65 0 00-.64-.528H7.528z"></path></g></svg></span>申请转载</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots" class="Zi Zi--Dots Button-zi" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></span></button></div></div></div></div></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="//www.zhihu.com/column/sampleNLP"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="https://pic1.zhimg.com/v2-cf2f08378ff4485aa0a4ae98a8681f89_xs.jpg?source=172ae18b" srcSet="https://pic1.zhimg.com/v2-cf2f08378ff4485aa0a4ae98a8681f89_l.jpg?source=172ae18b 2x" alt="简单NLP"/></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><span><a class="ColumnLink ColumnItem-Title" href="//www.zhihu.com/column/sampleNLP"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">简单NLP</div></div></a></span></h2><div class="ContentItem-meta">致力于简单描述复杂的NLP。</div></div></div></div></ul></div></div><style data-emotion-css="u1frr4">.css-u1frr4{width:724px;}.css-u1frr4 .Modal-content{margin:22px 0 5px;}.css-u1frr4 .Creator-QuestionShared-title{padding-right:65px;}</style></div></main></div></div><script id="js-clientConfig" type="text/json">{"fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","lens":"https:\u002F\u002Flens.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com","walletpay":"https:\u002F\u002Fwalletpay.zhihu.com","captcha":"https:\u002F\u002Fcaptcha.zhihu.com","vzuu":"https:\u002F\u002Fv.vzuu.com","openapi":"https:\u002F\u002Fopenapi.zhihu.com","svip":"https:\u002F\u002Fsvip.zhihu.com"},"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","videoHost":"video.zhihu.com","allowSignUp":true}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false,"article\u002FloadPostSearchEntity\u002F":false}},"club":{"tags":{},"admins":{"data":[]},"members":{"data":[]},"explore":{"candidateSyncClubs":{}},"profile":{},"checkin":{},"comments":{"paging":{},"loading":{},"meta":{},"ids":{}},"postList":{"paging":{},"loading":{},"ids":{}},"recommend":{"data":[]},"silences":{"data":[]},"application":{"profile":null}},"entities":{"users":{"robin-feng-41":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2b66bc8b3dab8cac5bb1d5a714bb1f32.jpg?source=172ae18b","uid":"710784923966926848","userType":"people","isFollowing":false,"urlToken":"robin-feng-41","id":"cdab13bba6b31ed86bc42b55e49ed787","description":"算法工程师","name":"Leslie","isAdvertiser":false,"headline":"研究NLP方向。","gender":1,"url":"\u002Fpeople\u002Fcdab13bba6b31ed86bc42b55e49ed787","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-2b66bc8b3dab8cac5bb1d5a714bb1f32_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"972475023013875712","medalName":"有口皆碑","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-13cd44de0025e34576038008bf13e26f_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-13cd44de0025e34576038008bf13e26f_l.png?source=172ae18b","description":"获得 1000 个赞同","medalAvatarFrame":""}}},"questions":{},"answers":{},"articles":{"52119092":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fcontent_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=BiBUKF0xBSkqGGJ-QhvjYHlDBQ==&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__&zid=__ZONEID__"],"entityWords":[{"name":"注意力机制","mention":"注意力机制","matchorder":1,"begin":5346,"end":5351,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Psychology","score":5.6011336967495815,"attachedInfoBytes":"sgJdCg\u002Fms6jmhI\u002FlipvmnLrliLYSClBzeWNob2xvZ3kY4ikg5ykoATV9PLNAOgdhcnRpY2xlQABIAFIkNWQ5MmE5ZWYtODc4NS00YWY2LTlmMWItOTVkOTcwYmNmZmM1","isOnAB":false,"isNatural":1},{"name":"源语言","mention":"源语言","matchorder":1,"begin":3803,"end":3806,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":3.921393747598433,"attachedInfoBytes":"sgJWCgnmupDor63oqIASCU90aGVyVGVybRjbHSDeHSgBNR34ekA6B2FydGljbGVAAEgAUiQ1ZDkyYTllZi04Nzg1LTRhZjYtOWYxYi05NWQ5NzBiY2ZmYzU=","isOnAB":false,"isNatural":1},{"name":"softmax","mention":"softmax","matchorder":1,"begin":6534,"end":6541,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Math","score":2.9736143324650834,"attachedInfoBytes":"sgJPCgdzb2Z0bWF4EgRNYXRoGIYzII0zKAE1sk8+QDoHYXJ0aWNsZUAASABSJDVkOTJhOWVmLTg3ODUtNGFmNi05ZjFiLTk1ZDk3MGJjZmZjNQ==","isOnAB":false,"isNatural":1},{"name":"机器学习","mention":"机器学习","matchorder":1,"begin":4979,"end":4983,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Computer","score":0.19114917390697794,"attachedInfoBytes":"sgJYCgzmnLrlmajlrabkuaASCENvbXB1dGVyGPMmIPcmKAE1nLxDPjoHYXJ0aWNsZUAASABSJDVkOTJhOWVmLTg3ODUtNGFmNi05ZjFiLTk1ZDk3MGJjZmZjNQ==","isOnAB":false,"isNatural":1},{"name":"前馈神经网络","mention":"前馈神经网络","matchorder":1,"begin":559,"end":565,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":7.1237523888205025,"attachedInfoBytes":"sgJfChLliY3ppojnpZ7nu4\u002FnvZHnu5wSCU90aGVyVGVybRivBCC1BCgBNcj140A6B2FydGljbGVAAEgAUiQ1ZDkyYTllZi04Nzg1LTRhZjYtOWYxYi05NWQ5NzBiY2ZmYzU=","isOnAB":false,"isNatural":1},{"name":"语义编码","mention":"语义编码","matchorder":1,"begin":4699,"end":4703,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Computer","score":6.184626860245381,"attachedInfoBytes":"sgJYCgzor63kuYnnvJbnoIESCENvbXB1dGVyGNskIN8kKAE1d+jFQDoHYXJ0aWNsZUAASABSJDVkOTJhOWVmLTg3ODUtNGFmNi05ZjFiLTk1ZDk3MGJjZmZjNQ==","isOnAB":false,"isNatural":1}],"id":52119092,"title":"NLP中的RNN、Seq2Seq与attention注意力机制","type":"article","articleType":"normal","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F52119092","imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-4f760232b1cd7ab29749948a3656b027_720w.jpg?source=172ae18b","titleImage":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4f760232b1cd7ab29749948a3656b027_720w.jpg?source=172ae18b","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-72ca7955f773b0ad95ddb7430ccc8e7d_200x112.jpg\" data-caption=\"RNN结构图\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"776\" data-watermark=\"watermark\" data-original-src=\"v2-72ca7955f773b0ad95ddb7430ccc8e7d\" data-watermark-src=\"v2-aa1137939edb1de9a6230f7b910f0209\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-72ca7955f773b0ad95ddb7430ccc8e7d_r.jpg\"\u002F\u003E\u003Cb\u003ERNN循环神经网络\u003C\u002Fb\u003ERNN循环神经网络被广泛应用于自然语言处理中，对于处理序列数据有很好的效果，常见的序列数据有文本、语音等，至于为什么要用到循环神经网络而不是传统的神经网络，我们在这里举一个例子。 假如有一个智能订票系统，我只需要输入一句话，该…","created":1544517318,"updated":1565621700,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2b66bc8b3dab8cac5bb1d5a714bb1f32.jpg?source=172ae18b","uid":"710784923966926848","userType":"people","isFollowing":false,"urlToken":"robin-feng-41","id":"cdab13bba6b31ed86bc42b55e49ed787","description":"算法工程师","name":"Leslie","isAdvertiser":false,"headline":"研究NLP方向。","gender":1,"url":"\u002Fpeople\u002Fcdab13bba6b31ed86bc42b55e49ed787","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-2b66bc8b3dab8cac5bb1d5a714bb1f32_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"972475023013875712","medalName":"有口皆碑","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-13cd44de0025e34576038008bf13e26f_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-13cd44de0025e34576038008bf13e26f_l.png?source=172ae18b","description":"获得 1000 个赞同","medalAvatarFrame":""}},"commentPermission":"all","copyrightPermission":"need_review","state":"published","ipInfo":"","imageWidth":742,"imageHeight":354,"content":"\u003Ch2\u003E\u003Cb\u003ERNN循环神经网络\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp data-pid=\"VGw3beqC\"\u003ERNN循环神经网络被广泛应用于自然语言处理中，对于处理序列数据有很好的效果，常见的序列数据有文本、语音等，至于为什么要用到循环神经网络而不是传统的神经网络，我们在这里举一个例子。\u003C\u002Fp\u003E\u003Cp data-pid=\"cY91hFhC\"\u003E假如有一个智能订票系统，我只需要输入一句话，该系统能识别出我将在什么时间订购去哪里的车票。那么程序需要根据我们输入的文本识别出我们出发的时间，目的地以及始发地。\u003C\u002Fp\u003E\u003Cp data-pid=\"9ehhIXRk\"\u003E如:我一月一号去郑州。\u003C\u002Fp\u003E\u003Cp data-pid=\"rZaFDwvZ\"\u003E那么“一月一号”是时间，“郑州”是目的地，“我”和“去”都是其他不需要提取的信息，我们统一归为其他类。\u003C\u002Fp\u003E\u003Cp data-pid=\"rWmBLFo4\"\u003E那么假如我输入另外一个句子:\u003C\u002Fp\u003E\u003Cp data-pid=\"VYYyzYZ2\"\u003E我一月一号离开郑州\u003C\u002Fp\u003E\u003Cp data-pid=\"tEmkERym\"\u003E此时“一月一号”是时间，“郑州”就变成了始发地，“我”和“离开”都是其他。\u003C\u002Fp\u003E\u003Cp data-pid=\"iOkImX4C\"\u003E针对这个例子，我输入不同的文本，郑州表示为不同的label,用前馈神经网络去做的话，就不能将两个不同语境下的“郑州”区分开，所以这时我们需要我们的神经网络具有记忆功能，即，当在看到第一个文本中的“郑州”的时候，神经网络已经存储了“去”这个词的信息。当在看到第二个文本中的“郑州”的时候就已经存储了“离开”这个词的信息，因为“去”和“离开”两个词的信息不同，故就可以将两个文本中的“郑州”区分开。\u003C\u002Fp\u003E\u003Cp data-pid=\"fLr5ABzJ\"\u003E下面我们根据这个例子去了解循环神经网络的结构\u003C\u002Fp\u003E\u003Cp data-pid=\"e7TxQHi2\"\u003E对于一个文本的每一个词可以看做是一个时序。RNN的每一个时序是一个前馈神经网络，但是为了在每一个时刻都包含前边时序的信息，所以RNN的每个时序共享了隐藏层，即当前时刻的输入不仅包含了当前时刻的词，还包含了前一时刻的隐藏层的输出。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-aa1137939edb1de9a6230f7b910f0209_b.jpg\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"776\" class=\"origin_image zh-lightbox-thumb\" width=\"1920\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-aa1137939edb1de9a6230f7b910f0209_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1920&#39; height=&#39;776&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"776\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1920\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-aa1137939edb1de9a6230f7b910f0209_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-aa1137939edb1de9a6230f7b910f0209_b.jpg\"\u002F\u003E\u003Cfigcaption\u003ERNN结构图\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"8-95VvaH\"\u003E因为计算机并不能读懂汉字，所以我们一般会用向量的方式去表示一个词。\u003C\u002Fp\u003E\u003Cp data-pid=\"3a3I-je9\"\u003E向量表示词的方法有很多，常用的比如one-hot、词袋模型、词嵌入等。\u003C\u002Fp\u003E\u003Cp data-pid=\"Uo2FIDEC\"\u003E在本例中为了方便计算在这里我们使用：\u003C\u002Fp\u003E\u003Cp data-pid=\"ChK9aTxq\"\u003E[1,1]表示我\u003C\u002Fp\u003E\u003Cp data-pid=\"1ro3z3qR\"\u003E[2,2]表示去\u003C\u002Fp\u003E\u003Cp data-pid=\"uIbcMoO4\"\u003E[3,3]表示离开\u003C\u002Fp\u003E\u003Cp data-pid=\"UwjZ-bsk\"\u003E[4,4]表示郑州\u003C\u002Fp\u003E\u003Cp data-pid=\"QB5AnuDF\"\u003E并且假设所有的权重都是1，所有的偏置都是0。\u003C\u002Fp\u003E\u003Cp data-pid=\"kGLecYsV\"\u003E下图为“我去郑州”的循环神经网络结构图。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-73730b3454aee066f0d0355ff2051f6c_b.jpg\" data-size=\"normal\" data-rawwidth=\"744\" data-rawheight=\"435\" class=\"origin_image zh-lightbox-thumb\" width=\"744\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-73730b3454aee066f0d0355ff2051f6c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;744&#39; height=&#39;435&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"744\" data-rawheight=\"435\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"744\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-73730b3454aee066f0d0355ff2051f6c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-73730b3454aee066f0d0355ff2051f6c_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E我去郑州\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-610a0575cb798e88c4fe471c9eafb19a_b.jpg\" data-size=\"normal\" data-rawwidth=\"748\" data-rawheight=\"430\" class=\"origin_image zh-lightbox-thumb\" width=\"748\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-610a0575cb798e88c4fe471c9eafb19a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;748&#39; height=&#39;430&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"748\" data-rawheight=\"430\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"748\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-610a0575cb798e88c4fe471c9eafb19a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-610a0575cb798e88c4fe471c9eafb19a_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E我离开郑州\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"8iETW872\"\u003E下图为“我离开郑州”的循环神经网络结构图。\u003C\u002Fp\u003E\u003Cp data-pid=\"dUlbrCg1\"\u003E我们看到，因为“去”和“离开”的词向量不同，所以在循环神经网络中最后的“郑州”的输出也不相同，这样就能把两个“郑州”给区分开来了。\u003C\u002Fp\u003E\u003Cp data-pid=\"0-ptZDQT\"\u003E根据上边的例子可以看出来，循环神经网络中每一个时序的隐藏层不仅包含了前边时序的输入信息，也包含了前边时序的顺序信息。可以理解为包含了前边时序的语义信息。\u003C\u002Fp\u003E\u003Cp data-pid=\"4Turc4Np\"\u003E循环神经网络展开图:\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8bb4944dbeb62636ce52b299dc72af47_b.jpg\" data-size=\"normal\" data-rawwidth=\"484\" data-rawheight=\"229\" class=\"origin_image zh-lightbox-thumb\" width=\"484\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8bb4944dbeb62636ce52b299dc72af47_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;484&#39; height=&#39;229&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"484\" data-rawheight=\"229\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"484\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8bb4944dbeb62636ce52b299dc72af47_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8bb4944dbeb62636ce52b299dc72af47_b.jpg\"\u002F\u003E\u003Cfigcaption\u003ERNN展开图\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"ruRCJGD7\"\u003E可以看出，每一个时刻的输出不仅包含了该时刻的输入向量，也包含了前一时刻的隐藏层的输出。具体的计算公式如下:\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5616fcfed2821b4667430325048b572f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"225\" data-rawheight=\"59\" class=\"content_image\" width=\"225\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;225&#39; height=&#39;59&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"225\" data-rawheight=\"59\" class=\"content_image lazy\" width=\"225\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5616fcfed2821b4667430325048b572f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-fccd1aa7bb7e1d12a398146ff449d9c1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"421\" data-rawheight=\"63\" class=\"origin_image zh-lightbox-thumb\" width=\"421\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-fccd1aa7bb7e1d12a398146ff449d9c1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;421&#39; height=&#39;63&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"421\" data-rawheight=\"63\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"421\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-fccd1aa7bb7e1d12a398146ff449d9c1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-fccd1aa7bb7e1d12a398146ff449d9c1_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003E\u003Cb\u003Eseq2seq模型\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp data-pid=\"7JTRY3im\"\u003E刚才的例子其实是N对N的循环神经网络，即我的输入序列长度是N,输出也是对应的N长度的序列。其实循环神经网络还有其他的比如:1对N、N对1。\u003C\u002Fp\u003E\u003Cp data-pid=\"sRhisK1s\"\u003E但很多时候我们会遇到输入序列和输出序列不等长的例子但又不是1对N和N对1，如机器翻译，智能问答，源语言和目标语言的句子往往并没有相同的长度。为此我们引出RNN最重要的一个变种：N vs M。这种结构又叫Encoder-Decoder模型，也可以称之为Seq2Seq模型。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5c62edab9ef404f1802c9637fcafbfaf_b.jpg\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"289\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5c62edab9ef404f1802c9637fcafbfaf_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;720&#39; height=&#39;289&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"289\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"720\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5c62edab9ef404f1802c9637fcafbfaf_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5c62edab9ef404f1802c9637fcafbfaf_b.jpg\"\u002F\u003E\u003Cfigcaption\u003Eseq2seq模型\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"pPSzza8C\"\u003E还有一种做法是将c当做每一步的输入：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6d615b290998f8c44bc46782b244bf2f_b.jpg\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"398\" class=\"origin_image zh-lightbox-thumb\" width=\"720\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6d615b290998f8c44bc46782b244bf2f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;720&#39; height=&#39;398&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"720\" data-rawheight=\"398\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"720\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6d615b290998f8c44bc46782b244bf2f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6d615b290998f8c44bc46782b244bf2f_b.jpg\"\u002F\u003E\u003Cfigcaption\u003Eseq2seq模型\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"XMoAja5_\"\u003E对于序列到序列的数据来说，可以把Encoder和Decoder分别看成是RNN，在Encoder中根据输入数据生成一个语义编码C，C的获取方式有很多种，最简单的就是把Encoder中最后一个隐藏层赋值给C，也可以对最后一个隐藏状态做一个变换得到C，还可以对所有的隐藏状态做变换得到C。\u003C\u002Fp\u003E\u003Cp data-pid=\"wxpwyk55\"\u003E拿到C之后，就可以用另一个RNN进行解码，这部分RNN被称为Decoder，具体做法就是将C当做之前的初始状态h0输入到Decoder中，C还有一种做法是将C当做每一步的输入。\u003C\u002Fp\u003E\u003Cp data-pid=\"_7utBpjN\"\u003E这里我们用一个机器翻译的例子解释seq2seq模型。\u003C\u002Fp\u003E\u003Cp data-pid=\"jTvYOke9\"\u003E例:机器学习翻译 成 machine learning\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ed423dc7c4354adce7612d8db77f19ca_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"694\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb\" width=\"694\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ed423dc7c4354adce7612d8db77f19ca_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;694&#39; height=&#39;338&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"694\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"694\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ed423dc7c4354adce7612d8db77f19ca_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ed423dc7c4354adce7612d8db77f19ca_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003E\u003Cb\u003EAttention（注意力机制）\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp data-pid=\"TB0tZqS2\"\u003E图片展示的Encoder-Decoder框架是没有体现“注意力模型”的，所以可以把它看做是注意力不集中分心模型。因为在生成目标句子的单词时，不论生成哪个单词，它们使用的输入句子的语义编码C都是一样的，没有任何区别。而语义编码C是由原句子中的每个单词经过Encoder编码产生的，这意味着原句子中任意单词对生成某个目标单词来说影响力都是相同的，这就是模型没有体现出注意力的缘由。\u003C\u002Fp\u003E\u003Cp data-pid=\"_TVfz-Xl\"\u003E在上边那个例子中在生成“machine”时，&#34;机&#34;,&#34;器&#34;,&#34;学&#34;,&#34;&#34;习&#34;的贡献是相同的，很明显，这是不太合理，显然，&#34;机&#34;,&#34;器&#34;，对于翻译成&#34;machine&#34;更为重要。所以我们希望在模型翻译&#34;machine&#34;的时候，&#34;机&#34;，&#34;器&#34;两个字的贡献(权重)更大，当在翻译成&#34;learning&#34;时，&#34;学&#34;，&#34;习&#34;两个字贡献(权重)更大。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9407244671e4bc4fa32da7e66fba25bf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"747\" data-rawheight=\"189\" class=\"origin_image zh-lightbox-thumb\" width=\"747\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9407244671e4bc4fa32da7e66fba25bf_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;747&#39; height=&#39;189&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"747\" data-rawheight=\"189\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"747\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9407244671e4bc4fa32da7e66fba25bf_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-9407244671e4bc4fa32da7e66fba25bf_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"C0GIj2as\"\u003E上图中，输入序列上是“机器学习”，因此Encoder中的h1、h2、h3、h4分别代表“机&#34;,&#34;器&#34;,&#34;学&#34;,&#34;习”的信息，在翻译&#34;macine&#34;时，第一个上下文向量C1应该和&#34;机&#34;,&#34;器&#34;两个字最相关，所以对应的权重a比较大，在翻译&#34;learning&#34;时，第二个上下文向量C2应该和&#34;学&#34;,&#34;习&#34;两个字最相关，所以&#34;学&#34;,&#34;习&#34;对应的权重a比较大。\u003C\u002Fp\u003E\u003Cp data-pid=\"blfAY9DT\"\u003Ea其实是一个0-1之间的值，a可以看成是e的softmax后的结果。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-78c7c4bcfeee2842321c93494f4d5fe3_b.jpg\" data-size=\"normal\" data-rawwidth=\"761\" data-rawheight=\"434\" class=\"origin_image zh-lightbox-thumb\" width=\"761\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-78c7c4bcfeee2842321c93494f4d5fe3_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;761&#39; height=&#39;434&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"761\" data-rawheight=\"434\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"761\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-78c7c4bcfeee2842321c93494f4d5fe3_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-78c7c4bcfeee2842321c93494f4d5fe3_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E翻译matchine\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1439a5032b0997ef3e5861359026b2ea_b.jpg\" data-size=\"normal\" data-rawwidth=\"754\" data-rawheight=\"423\" class=\"origin_image zh-lightbox-thumb\" width=\"754\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1439a5032b0997ef3e5861359026b2ea_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;754&#39; height=&#39;423&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"754\" data-rawheight=\"423\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"754\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1439a5032b0997ef3e5861359026b2ea_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-1439a5032b0997ef3e5861359026b2ea_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E翻译learning\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"08RRJj55\"\u003E那现在关于\u003Cb\u003Eattention\u003C\u002Fb\u003E来说就只剩下一个问题了，就是e是怎么来的。关于e的计算，业界有很多种方法，常用的有以下三种方式:\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2dabbf1328362b4e2354f29b2dd210bf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"377\" data-rawheight=\"148\" class=\"content_image\" width=\"377\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;377&#39; height=&#39;148&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"377\" data-rawheight=\"148\" class=\"content_image lazy\" width=\"377\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2dabbf1328362b4e2354f29b2dd210bf_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Col\u003E\u003Cli data-pid=\"qX1nvcaI\"\u003E计算Encoder的序列h与Decoder的序列h的余弦相似度.\u003C\u002Fli\u003E\u003Cli data-pid=\"BbgwB1xN\"\u003E在1的基础上，乘上一个Wa，Wa是需要学习的参数，从学习到Encoder和Decoder的隐藏的打分e。\u003C\u002Fli\u003E\u003Cli data-pid=\"yKxQ2fRC\"\u003E设计一个前馈神经网络，前馈神经网络的输入是Encoder和Decoder的两个隐藏状态，Va、Wa都是需要学习的参数。\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Ch2\u003E总结\u003C\u002Fh2\u003E\u003Cp data-pid=\"3oqt3NNF\"\u003E     到这里，本文已经介绍了RNN循环神经网络的基本概念，seq2seq模型的基本概念及seq2seq中的注意力机制，希望能帮到大家。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E引用\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp data-pid=\"AJt4XDJA\"\u003E本文关于\u003Cb\u003Eseq2seq\u003C\u002Fb\u003E模型中的三张图引用了\u003Cb\u003E\u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F28054589\" class=\"internal\"\u003E完全图解RNN、RNN变体、Seq2Seq、Attention机制\u003C\u002Fa\u003E，\u003C\u002Fb\u003E在此表示感谢\u003Cb\u003E。\u003C\u002Fb\u003E\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20086967","type":"topic","id":"20086967","name":"RNN"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20682987","type":"topic","id":"20682987","name":"注意力机制"}],"voteupCount":148,"voting":0,"heavyUpStatus":"allow_heavy_up","column":{"description":"","canManage":false,"intro":"致力于简单描述复杂的NLP。","isFollowing":false,"urlToken":"sampleNLP","id":"sampleNLP","articlesCount":9,"acceptSubmission":true,"title":"简单NLP","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002FsampleNLP","commentPermission":"all","created":1538301779,"updated":1591433467,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-cf2f08378ff4485aa0a4ae98a8681f89_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2b66bc8b3dab8cac5bb1d5a714bb1f32.jpg?source=172ae18b","uid":"710784923966926848","userType":"people","isFollowing":false,"urlToken":"robin-feng-41","id":"cdab13bba6b31ed86bc42b55e49ed787","description":"算法工程师","name":"Leslie","isAdvertiser":false,"headline":"研究NLP方向。","gender":1,"url":"\u002Fpeople\u002Fcdab13bba6b31ed86bc42b55e49ed787","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2b66bc8b3dab8cac5bb1d5a714bb1f32_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":85,"type":"column"},"commentCount":9,"contributions":[{"id":2670266,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"致力于简单描述复杂的NLP。","isFollowing":false,"urlToken":"sampleNLP","id":"sampleNLP","articlesCount":9,"acceptSubmission":true,"title":"简单NLP","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002FsampleNLP","commentPermission":"all","created":1538301779,"updated":1591433467,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-cf2f08378ff4485aa0a4ae98a8681f89_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2b66bc8b3dab8cac5bb1d5a714bb1f32.jpg?source=172ae18b","uid":"710784923966926848","userType":"people","isFollowing":false,"urlToken":"robin-feng-41","id":"cdab13bba6b31ed86bc42b55e49ed787","description":"算法工程师","name":"Leslie","isAdvertiser":false,"headline":"研究NLP方向。","gender":1,"url":"\u002Fpeople\u002Fcdab13bba6b31ed86bc42b55e49ed787","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2b66bc8b3dab8cac5bb1d5a714bb1f32_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":85,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":false,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"favlistsCount":298,"isNormal":true,"status":0,"shareText":"NLP中的RNN、Seq2Seq与attention注意力机制 - 来自知乎专栏「简单NLP」，作者: Leslie https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F52119092 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":39,"hasColumn":true,"republishers":[],"isNewLinkCard":true,"emojiReaction":{"cryFaceCount":0,"cryFaceHasSet":false,"hugCount":0,"hugHasSet":false,"likeCount":39,"likeHasSet":false,"onlookerCount":0,"onlookerHasSet":false},"abParam":{"shangyebiaoshi":"1"},"attachedInfo":"kgIiCggxMDY0MjcwMxIINTIxMTkwOTIYByIKSU1BR0VfVEVYVA==","settings":{"tableOfContents":{"enabled":false}},"canReference":false,"reactionInstruction":{}}},"columns":{"sampleNLP":{"description":"","canManage":false,"intro":"致力于简单描述复杂的NLP。","isFollowing":false,"urlToken":"sampleNLP","id":"sampleNLP","articlesCount":9,"acceptSubmission":true,"title":"简单NLP","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002FsampleNLP","commentPermission":"all","created":1538301779,"updated":1591433467,"imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-cf2f08378ff4485aa0a4ae98a8681f89_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2b66bc8b3dab8cac5bb1d5a714bb1f32.jpg?source=172ae18b","uid":"710784923966926848","userType":"people","isFollowing":false,"urlToken":"robin-feng-41","id":"cdab13bba6b31ed86bc42b55e49ed787","description":"算法工程师","name":"Leslie","isAdvertiser":false,"headline":"研究NLP方向。","gender":1,"url":"\u002Fpeople\u002Fcdab13bba6b31ed86bc42b55e49ed787","avatarUrl":"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2b66bc8b3dab8cac5bb1d5a714bb1f32_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":85,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{},"zvideos":{},"zvideoContributions":{},"briefs":{},"eduCourses":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false},"cardUserInfo":{"vipInfo":{}},"handleWidget":{},"widgetList":[],"userWidgetId":""},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{},"infinity":{},"batchUsers":{},"profileInfinity":null},"env":{"ab":{"config":{"params":[{"id":"vessay_v2_sdk","type":"Int","value":"1","layerId":"Qtkm"},{"id":"pc_ppt_publish","type":"Int","value":"0","layerId":"pc_ppt_publish"},{"id":"titlepagechoose","type":"Int","value":"0","layerId":"titlepagechoose"},{"id":"helpcenter_pc","type":"Int","value":"0","layerId":"helpcenter_pc"},{"id":"pc_comment","type":"Int","value":"0","layerId":"EsOR"},{"id":"pc_follow","type":"Int","value":"0","layerId":"pc_follow"},{"id":"draftsentrance","type":"Int","value":"1","layerId":"draftsentrance"}],"experiments":[{"expId":"pc_follow-2_v4","expPrefix":"pc_follow","isDynamicallyUpdated":false,"isRuntime":false,"includeTriggerInfo":false}],"chains":[{"chainId":"_all_"}],"encodedParams":"CoQCGwA\u002FAEMARwC0AEABaQFqAXQBOwK5AswC1wLYAjIDTwNQA6ADoQOiA7cD8wP0AzMEjASNBKYE1gQRBSkFMgVRBYsFjAWeBRYGMAYxBkEGfgaUBqIG6wYnB1cHdwd4B5sH2AfcB90HJwhnCHQIdgh5CMUI1gjaCOUIAQk\u002FCUIJVAlVCWAJjQmrCcMJxAnFCcYJxwnICckJygnLCcwJ0QnlCfEJ9AkECkkKZQprCoMKmAqlCqkKvgrECtQK3QrtCv0K\u002FgopCzsLPAtDC0YLcQt2C4ULhwuNC7kLwAvXC+AL5QvmCywMOAxxDI8MNAzcC2ALAQubC7UL5ArgC+wKUgtWDLQKNwwSggEAABgAAAAAAAAACwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMAAAEBAQAB"},"triggers":{}},"userAgent":{"Edge":false,"IE":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Quark":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"WxMiniProgram":false,"BaiduMiniProgram":false,"QQMiniProgram":false,"JDMiniProgram":false,"isWebView":false,"isMiniProgram":false,"origin":"Mozilla\u002F5.0 (X11; Linux aarch64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Typora\u002F1.2.3 Chrome\u002F98.0.4758.109 Electron\u002F17.1.2 Safari\u002F537.36"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F52119092","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F52119092","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"beijing":false,"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false,"baiduSearch":false,"googleSearch":false,"shenma":false,"miniProgram":false,"xiaomi":false},"theme":"light","appHeaderTheme":{"current":"normal","disable":true,"normal":{"bgColor":"GBK99A"},"custom":{"bgColor":"GBK99A"}},"enableShortcut":true,"referer":"","xUDId":"AHARqbBwTxWPThsTpsaESHaDdsNJ50aGFZE=","mode":"ssr","conf":{},"xTrafficFreeOrigin":"","ipInfo":{"cityName":"","countryName":"中国","regionName":"中国","countryCode":"CN"},"logged":false,"vars":{"passThroughHeaders":{}}},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"newRights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{},"videoSupport":{},"textBenefit":{},"mcnManage":{},"tasks":{},"newTasks":{"creatorTask":{"tasks":[],"des":[]}},"scoreInfo":{},"recentlyCreated":[],"analysis":{"all":{},"answer":{},"zvideo":{},"article":{},"pin":{},"singleContent":{}},"announcement":{},"bannerList":[],"school":{"tabs":[],"contents":[],"banner":null,"entities":{}},"creatorsRecommendInfo":{},"menusShowControlByServer":{"bVipRecomend":false,"creationRelationship":false},"income":{"aggregation":{}}},"answers":{"voters":{},"copyrightApplicants":{},"favlists":{},"newAnswer":{},"entityWords":{},"concernedUpvoters":{},"simpleConcernedUpvoters":{},"paidContent":{},"settings":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{},"concernedUpvoters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"room":{"meta":{},"isFetching":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]},"hotDaily":{"data":[],"paging":{}},"hotHighlight":{"isFetching":false,"isDrained":false,"data":[],"paging":{}},"banner":{},"commercialBanner":{"show":false,"banner":{},"trackData":{}},"video":{"items":[],"next":null,"isLoading":false,"isDrained":false}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"sampleNLP"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"userProfit":{"permission":{"permissionStatus":{"zhiZixuan":0,"recommend":-1,"task":0,"plugin":0,"infinity":0},"visible":false}},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[],"lists":{},"banners":{},"protocolStatus":{"isAgreedNew":true,"isAgreedOld":true},"probationCountdownDays":0},"zvideos":{"campaignVideoList":{},"campaigns":{},"tagoreCategory":[],"recommendations":{},"insertable":{},"recruit":{"form":{"platform":"","nickname":"","followerCount":"","domain":"","contact":""},"submited":false,"ranking":[]},"club":{},"qyActivityData":{},"talkActivityData":{},"party2022ActivityData":{},"batchVideos":{},"contribution":{"selectedContribution":null,"campaign":null,"configs":{},"contributionLists":{},"recommendQuestions":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]},"questionSearchResults":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]}},"creationReferences":{},"zvideoCollection":{},"zvideoGrant":{},"collectData":{"isFetching":false,"list":[]},"videoSource":{"isLoaded":false}},"republish":{},"commentPermission":{},"creatorRightStatus":{"list":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script crossorigin="" src="https://static.zhihu.com/heifetz/vendor.4bb309fcb0b4b803488b.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/column.lib_09e9ad9b.cf29a9cc273a9d3961d7.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/column.lib_79b5cf47.1419adbd3890e66b0630.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/column.lib_29107295.92776c3e8a21baf92d06.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/column.lib_0ad37f8a.3f5df7eb0d146a5b06e2.js"></script><script crossorigin="" src="https://static.zhihu.com/heifetz/column.app.848a9632ad3cc06c3760.js"></script><script defer="" src="https://static.zhihu.com/event/wza/31035/aria.js?appid=a3637ace5dc3a347f6863b0bac487599"></script></body><script src="https://hm.baidu.com/hm.js?98beee57fd2ef70ccdd5ca52b9740c49" async=""></script></html>